# λ¨λΈ ν‰κ°€ κΈ°λ²• μ™„λ²½ κ°€μ΄λ“: ν™€λ“μ•„μ›ƒ, K-ν΄λ“, λ¶€νΈμ¤νΈλ©, λ¬΄μ‘μ„ μ„λΈμƒν”λ§

## λ©μ°¨
1. [κΈ°λ³Έ κ°λ…](#1-κΈ°λ³Έ-κ°λ…)
2. [ν™€λ“μ•„μ›ƒ (Hold-out)](#2-ν™€λ“μ•„μ›ƒ-hold-out)
3. [K-ν΄λ“ κµμ°¨κ²€μ¦ (K-Fold Cross-Validation)](#3-k-ν΄λ“-κµμ°¨κ²€μ¦-k-fold-cross-validation)
4. [λ¶€νΈμ¤νΈλ© (Bootstrap)](#4-λ¶€νΈμ¤νΈλ©-bootstrap)
5. [λ¬΄μ‘μ„ μ„λΈμƒν”λ§ (Random Subsampling)](#5-λ¬΄μ‘μ„-μ„λΈμƒν”λ§-random-subsampling)
6. [μƒμ„Έ λΉ„κµ](#6-μƒμ„Έ-λΉ„κµ)
7. [μ„ νƒ κ°€μ΄λ“](#7-μ„ νƒ-κ°€μ΄λ“)
8. [Python κµ¬ν„](#8-python-κµ¬ν„)

---

## 1. κΈ°λ³Έ κ°λ…

### 1.1 μ™ λ¨λΈ ν‰κ°€κ°€ ν•„μ”ν•κ°€?

**λ¬Έμ **: ν•™μµ λ°μ΄ν„°λ΅ ν‰κ°€ν•λ©΄ κ³Όμ ν•© μ—¬λ¶€λ¥Ό μ• μ μ—†μ

```
ν›λ ¨ λ°μ΄ν„°λ΅ ν‰κ°€:
- λ¨λΈμ΄ μ΄λ―Έ λ³Έ λ°μ΄ν„°
- κ³Όμ ν•©λμ–΄λ„ λ†’μ€ μ„±λ¥
- μΌλ°ν™” μ„±λ¥μ„ μ• μ μ—†μ

ν•΄κ²°μ±…:
- ν•™μµμ— μ‚¬μ©ν•μ§€ μ•μ€ λ°μ΄ν„°λ΅ ν‰κ°€
- μΌλ°ν™” μ„±λ¥ μΈ΅μ •
```

### 1.2 λ°μ΄ν„° λ¶„ν• μ λ©μ 

**3κ°€μ§€ λ°μ΄ν„°μ…‹**:
```
μ „μ²΄ λ°μ΄ν„°
    β†“
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚ ν›λ ¨ μ„ΈνΈ (Training Set)      β”‚ β† λ¨λΈ ν•™μµ
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚ κ²€μ¦ μ„ΈνΈ (Validation Set)    β”‚ β† ν•μ΄νΌνλΌλ―Έν„° νλ‹
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚ ν…μ¤νΈ μ„ΈνΈ (Test Set)        β”‚ β† μµμΆ… μ„±λ¥ ν‰κ°€
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”

μ—­ν• :
- Training: νλΌλ―Έν„° ν•™μµ (κ°€μ¤‘μΉ, νΈν–¥)
- Validation: ν•μ΄νΌνλΌλ―Έν„° μ„ νƒ, λ¨λΈ μ„ νƒ
- Test: μµμΆ… μΌλ°ν™” μ„±λ¥ ν‰κ°€ (1λ²λ§ μ‚¬μ©)
```

### 1.3 ν‰κ°€ λ°©λ²•μ μΆ…λ¥

| λ°©λ²• | νΉμ§• | λ°μ΄ν„° ν™μ©λ„ |
|------|------|--------------|
| **ν™€λ“μ•„μ›ƒ** | 1λ² λ¶„ν•  | λ‚®μ |
| **K-ν΄λ“** | Kλ² λ¶„ν• , Kλ² ν•™μµ | λ†’μ |
| **λ¶€νΈμ¤νΈλ©** | λ³µμ›μ¶”μ¶, Bλ² λ°λ³µ | λ†’μ |
| **λ¬΄μ‘μ„ μ„λΈμƒν”λ§** | Nλ² λ¬΄μ‘μ„ λ¶„ν•  | μ¤‘κ°„ |

---

## 2. ν™€λ“μ•„μ›ƒ (Hold-out)

### 2.1 μ •μ

**ν™€λ“μ•„μ›ƒ**: λ°μ΄ν„°λ¥Ό ν›λ ¨ μ„ΈνΈμ™€ ν…μ¤νΈ μ„ΈνΈλ΅ **ν• λ²λ§** λ¶„ν• ν•μ—¬ ν‰κ°€

### 2.2 λ°©λ²•

```
μ „μ²΄ λ°μ΄ν„° (100%)
    β†“
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚   ν›λ ¨ μ„ΈνΈ        β”‚ ν…μ¤νΈ   β”‚
β”‚   70-80%          β”‚  20-30%  β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
         β†“               β†“
      λ¨λΈ ν•™μµ        μ„±λ¥ ν‰κ°€

λλ” 3-way split:
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚  ν›λ ¨     β”‚  κ²€μ¦     β”‚  ν…μ¤νΈ  β”‚
β”‚  60%     β”‚  20%     β”‚  20%     β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

**μ μ°¨**:
```python
1. λ°μ΄ν„° μ„κΈ° (shuffle)
2. λ¶„ν•  λΉ„μ¨ κ²°μ • (μ: 80:20)
3. ν›λ ¨/ν…μ¤νΈ μ„ΈνΈ λ¶„ν• 
4. ν›λ ¨ μ„ΈνΈλ΅ ν•™μµ
5. ν…μ¤νΈ μ„ΈνΈλ΅ ν‰κ°€
6. μ„±λ¥ μ§€ν‘ κ³„μ‚°
```

### 2.3 μ¥λ‹¨μ 

**μ¥μ **:
```
β“ κ°„λ‹¨ν•κ³  λΉ λ¦„
β“ κ³„μ‚° λΉ„μ© μµμ†
β“ κµ¬ν„ μ‰¬μ›€
β“ λ€μ©λ‰ λ°μ΄ν„°μ— μ ν•©
β“ μ‹¤μ „ λ°°ν¬ ν™κ²½κ³Ό μ μ‚¬
```

**λ‹¨μ **:
```
β— λ°μ΄ν„° ν™μ©λ„ λ‚®μ (μΌλ¶€λ§ ν•™μµμ— μ‚¬μ©)
β— λ¶„ν• μ— λ”°λΌ κ²°κ³Ό λ³€λ™μ„± νΌ
β— μ‘μ€ λ°μ΄ν„°μ…‹μ— λ¶€μ ν•©
β— νΈν–¥λ λ¶„ν•  κ°€λ¥μ„±
β— 1ν ν‰κ°€λ΅ μ‹ λΆ°λ„ λ‚®μ
```

### 2.4 μμ‹

```
λ°μ΄ν„°: 1,000κ° μƒν”

ν™€λ“μ•„μ›ƒ (80:20):
- ν›λ ¨: 800κ° β†’ λ¨λΈ ν•™μµ
- ν…μ¤νΈ: 200κ° β†’ μ„±λ¥ ν‰κ°€

λ¬Έμ μ :
λ§μ•½ ν…μ¤νΈ μ„ΈνΈκ°€ μ°μ—°ν μ‰¬μ΄ μƒν”λ§ ν¬ν•¨?
β†’ κ³Όλ€ν‰κ°€

λ§μ•½ ν…μ¤νΈ μ„ΈνΈκ°€ μ°μ—°ν μ–΄λ ¤μ΄ μƒν”λ§ ν¬ν•¨?
β†’ κ³Όμ†ν‰κ°€
```

### 2.5 λ¶„ν•  λΉ„μ¨ κ°€μ΄λ“

| λ°μ΄ν„° ν¬κΈ° | ν›λ ¨:ν…μ¤νΈ λΉ„μ¨ | μ΄μ  |
|-----------|----------------|------|
| **λ§¤μ° μ‘μ** (<1,000) | μ‚¬μ© μ• ν•¨ | K-ν΄λ“ κ¶μ¥ |
| **μ‘μ** (1K-10K) | 70:30 | ν…μ¤νΈ λ°μ΄ν„° ν™•λ³΄ |
| **μ¤‘κ°„** (10K-100K) | 80:20 | κ· ν• |
| **ν°** (100K-1M) | 90:10 | μ¶©λ¶„ν• ν…μ¤νΈ |
| **λ§¤μ° ν°** (>1M) | 95:5 λλ” 98:2 | μ‘μ€ λΉ„μ¨λ΅λ„ μ¶©λ¶„ |

### 2.6 Stratified Hold-out

**κ³„μΈµμ  λ¶„ν• **: ν΄λμ¤ λΉ„μ¨ μ μ§€

```
λ¶κ· ν• λ°μ΄ν„° μμ‹:
ν΄λμ¤ A: 900κ° (90%)
ν΄λμ¤ B: 100κ° (10%)

μΌλ° ν™€λ“μ•„μ›ƒ (λ¬Έμ ):
ν›λ ¨: A=720, B=80
ν…μ¤νΈ: A=180, B=20 (λΉ„μ¨ λ³€ν•  μ μμ)

Stratified ν™€λ“μ•„μ›ƒ (ν•΄κ²°):
ν›λ ¨: A=720 (90%), B=80 (10%)
ν…μ¤νΈ: A=180 (90%), B=20 (10%)
β†’ ν΄λμ¤ λΉ„μ¨ λ™μΌν•κ² μ μ§€
```

---

## 3. K-ν΄λ“ κµμ°¨κ²€μ¦ (K-Fold Cross-Validation)

### 3.1 μ •μ

**K-ν΄λ“**: λ°μ΄ν„°λ¥Ό Kκ° λ¶€λ¶„μ§‘ν•©(fold)μΌλ΅ λ‚λ„κ³ , κ°κ°μ„ ν• λ²μ”© ν…μ¤νΈ μ„ΈνΈλ΅ μ‚¬μ©ν•λ©° Kλ² ν‰κ°€

### 3.2 λ°©λ²•

```
μ „μ²΄ λ°μ΄ν„°λ¥Ό Kκ°λ΅ λ¶„ν• :

Fold 1 | Fold 2 | Fold 3 | Fold 4 | Fold 5
β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€

λ°λ³µ 1:
[Test] | [Train] | [Train] | [Train] | [Train] β†’ μ„±λ¥1
       
λ°λ³µ 2:
[Train] | [Test] | [Train] | [Train] | [Train] β†’ μ„±λ¥2

λ°λ³µ 3:
[Train] | [Train] | [Test] | [Train] | [Train] β†’ μ„±λ¥3

λ°λ³µ 4:
[Train] | [Train] | [Train] | [Test] | [Train] β†’ μ„±λ¥4

λ°λ³µ 5:
[Train] | [Train] | [Train] | [Train] | [Test] β†’ μ„±λ¥5

μµμΆ… μ„±λ¥ = (μ„±λ¥1 + μ„±λ¥2 + μ„±λ¥3 + μ„±λ¥4 + μ„±λ¥5) / 5
```

**μ μ°¨**:
```
1. λ°μ΄ν„°λ¥Ό Kκ° foldλ΅ λ¶„ν• 
2. for i in 1 to K:
   a. iλ²μ§Έ foldλ¥Ό ν…μ¤νΈ μ„ΈνΈλ΅
   b. λ‚λ¨Έμ§€ K-1κ° foldλ¥Ό ν›λ ¨ μ„ΈνΈλ΅
   c. λ¨λΈ ν•™μµ
   d. ν…μ¤νΈ μ„ΈνΈλ΅ ν‰κ°€ β†’ μ„±λ¥_i
3. ν‰κ·  μ„±λ¥ κ³„μ‚°: mean(μ„±λ¥_1, ..., μ„±λ¥_K)
4. ν‘μ¤€νΈμ°¨ κ³„μ‚°: std(μ„±λ¥_1, ..., μ„±λ¥_K)
```

### 3.3 μ¥λ‹¨μ 

**μ¥μ **:
```
β“ λ¨λ“  λ°μ΄ν„°κ°€ ν…μ¤νΈμ— 1λ²μ”© μ‚¬μ©
β“ λ°μ΄ν„° ν™μ©λ„ λ†’μ (100% ν™μ©)
β“ μ‹ λΆ°λ„ λ†’μ€ ν‰κ°€ (Kλ² ν‰κ· )
β“ λ¶„μ‚°(variance) μ¶”μ • κ°€λ¥
β“ μ‘μ€ λ°μ΄ν„°μ…‹μ— ν¨κ³Όμ 
β“ κ³Όμ ν•© μ—¬λ¶€ λ…ν™•ν νμ•…
```

**λ‹¨μ **:
```
β— κ³„μ‚° λΉ„μ© λ†’μ (Kλ² ν•™μµ)
β— μ‹κ°„ μ†μ” νΌ
β— λ€μ©λ‰ λ°μ΄ν„°μ— λ¶€λ‹΄
β— μµμΆ… λ¨λΈ μ„ νƒ ν•„μ” (Kκ° λ¨λΈ μ¤‘)
```

### 3.4 K κ°’ μ„ νƒ

| K κ°’ | νΉμ§• | μ μ© |
|------|------|------|
| **K=2** | 50:50 λ¶„ν•  | κ±°μ μ‚¬μ© μ• ν•¨ |
| **K=3** | λΉ λ¦„, λ‚®μ€ μ‹ λΆ°λ„ | μ΄κΈ° μ‹¤ν— |
| **K=5** | κ· ν•μ΅ν μ„ νƒ | **μΌλ°μ  μ¶”μ²** |
| **K=10** | ν‘μ¤€, λ†’μ€ μ‹ λΆ°λ„ | **λ§μ΄ μ‚¬μ©** |
| **K=20** | λ§¤μ° λ†’μ€ μ‹ λΆ°λ„ | μ‹κ°„ μ—¬μ  μμ„ λ• |
| **K=N** (LOOCV) | μµλ€ ν™μ© | λ§¤μ° μ‘μ€ λ°μ΄ν„° |

**K κ°’μ— λ”°λ¥Έ νΈλ μ΄λ“μ¤ν”„**:
```
Kκ°€ μ‘μ„μλ΅:
- λΉ λ¥Έ κ³„μ‚°
- λ‚®μ€ κ³„μ‚° λΉ„μ©
- λ†’μ€ νΈν–¥ (bias)
- λ‚®μ€ μ‹ λΆ°λ„

Kκ°€ ν΄μλ΅:
- λλ¦° κ³„μ‚°
- λ†’μ€ κ³„μ‚° λΉ„μ©
- λ‚®μ€ νΈν–¥
- λ†’μ€ μ‹ λΆ°λ„
- λ†’μ€ λ¶„μ‚° (variance)
```

### 3.5 λ³€ν•

#### 3.5.1 Stratified K-Fold

**νΉμ§•**: κ° foldμ—μ„ ν΄λμ¤ λΉ„μ¨ μ μ§€

```
λ¶κ· ν• λ°μ΄ν„°:
ν΄λμ¤ A: 90%, ν΄λμ¤ B: 10%

μΌλ° K-Fold (λ¬Έμ ):
Fold 1: A=95%, B=5%  β† λ¶κ· ν•
Fold 2: A=85%, B=15%

Stratified K-Fold (ν•΄κ²°):
Fold 1: A=90%, B=10% β† λΉ„μ¨ μ μ§€
Fold 2: A=90%, B=10%
...
```

#### 3.5.2 Leave-One-Out CV (LOOCV)

**μ •μ**: K=N (λ°μ΄ν„° κ°μ)

```
λ°μ΄ν„° 100κ° β†’ 100-Fold

λ°λ³µ 1: [99κ° ν›λ ¨] + [1κ° ν…μ¤νΈ]
λ°λ³µ 2: [99κ° ν›λ ¨] + [1κ° ν…μ¤νΈ]
...
λ°λ³µ 100: [99κ° ν›λ ¨] + [1κ° ν…μ¤νΈ]

ν‰κ·  = 100λ² κ²°κ³Όμ ν‰κ· 
```

**μ¥μ **:
- κ±°μ λ¨λ“  λ°μ΄ν„° μ‚¬μ© (N-1κ°)
- νΈν–¥ κ±°μ μ—†μ
- κ²°μ •λ΅ μ  (ν•­μƒ κ°™μ€ κ²°κ³Ό)

**λ‹¨μ **:
- λ§¤μ° λλ¦Ό (Nλ² ν•™μµ)
- λ†’μ€ λ¶„μ‚°
- λ€μ©λ‰ λ°μ΄ν„°μ— λ¶κ°€λ¥

#### 3.5.3 Repeated K-Fold

**νΉμ§•**: K-ν΄λ“λ¥Ό μ—¬λ¬ λ² λ°λ³µ (λ‹¤λ¥Έ λ¶„ν• λ΅)

```
5-Foldλ¥Ό 3λ² λ°λ³µ:
- 1ν: λ°μ΄ν„° μ„κ³  5-Fold β†’ 5κ° μ„±λ¥
- 2ν: λ‹¤μ‹ μ„κ³  5-Fold β†’ 5κ° μ„±λ¥
- 3ν: λ‹¤μ‹ μ„κ³  5-Fold β†’ 5κ° μ„±λ¥

μ΄ 15κ° μ„±λ¥ μ§€ν‘ β†’ ν‰κ· 

λ” μ•μ •μ μΈ μ¶”μ •
```

### 3.6 μμ‹

```
λ°μ΄ν„°: 1,000κ°

5-Fold:
Fold ν¬κΈ°: 1,000 / 5 = 200κ°

λ°λ³µ 1: ν›λ ¨ 800κ°, ν…μ¤νΈ 200κ° β†’ μ •ν™•λ„ 0.85
λ°λ³µ 2: ν›λ ¨ 800κ°, ν…μ¤νΈ 200κ° β†’ μ •ν™•λ„ 0.87
λ°λ³µ 3: ν›λ ¨ 800κ°, ν…μ¤νΈ 200κ° β†’ μ •ν™•λ„ 0.84
λ°λ³µ 4: ν›λ ¨ 800κ°, ν…μ¤νΈ 200κ° β†’ μ •ν™•λ„ 0.86
λ°λ³µ 5: ν›λ ¨ 800κ°, ν…μ¤νΈ 200κ° β†’ μ •ν™•λ„ 0.88

ν‰κ·  μ •ν™•λ„: (0.85 + 0.87 + 0.84 + 0.86 + 0.88) / 5 = 0.86
ν‘μ¤€νΈμ°¨: 0.015

κ²°λ΅ : 86.0% Β± 1.5%
```

---

## 4. λ¶€νΈμ¤νΈλ© (Bootstrap)

### 4.1 μ •μ

**λ¶€νΈμ¤νΈλ©**: **λ³µμ› μ¶”μ¶**λ΅ μ›λ³Έκ³Ό κ°™μ€ ν¬κΈ°μ μƒν”μ„ μƒμ„±ν•μ—¬ ν‰κ°€

### 4.2 λ°©λ²•

```
μ›λ³Έ λ°μ΄ν„°: Nκ°
    β†“
λ³µμ› μ¶”μ¶λ΅ Nκ° μƒν”λ§ (Bootstrap Sample)
    β†“
μ¤‘λ³µ κ°€λ¥! μΌλ¶€ μƒν”μ€ μ—¬λ¬ λ², μΌλ¶€λ” 0λ²

Bootstrap Sample 1: [1, 3, 3, 5, 7, 9, ...]
                     β†“
                  μ¤‘λ³µ μμ (3μ΄ 2λ²)

μ„ νƒ μ• λ μƒν” (Out-of-Bag): ν…μ¤νΈμ©

μ΄ κ³Όμ •μ„ Bλ² λ°λ³µ (λ³΄ν†µ B=100~1,000)
```

**μ μ°¨**:
```
1. for b in 1 to B:
   a. λ³µμ› μ¶”μ¶λ΅ Nκ° μƒν”λ§ β†’ ν›λ ¨ μ„ΈνΈ_b
   b. μ„ νƒ μ• λ μƒν” β†’ ν…μ¤νΈ μ„ΈνΈ_b (OOB)
   c. ν›λ ¨ μ„ΈνΈ_bλ΅ λ¨λΈ ν•™μµ
   d. ν…μ¤νΈ μ„ΈνΈ_bλ΅ ν‰κ°€ β†’ μ„±λ¥_b
2. ν‰κ·  μ„±λ¥ = mean(μ„±λ¥_1, ..., μ„±λ¥_B)
```

### 4.3 Out-of-Bag (OOB) μƒν”

**ν™•λ¥  κ³„μ‚°**:
```
μ›λ³Έ Nκ°, λ³µμ› μ¶”μ¶ Nλ²

ν• μƒν”μ΄ μ„ νƒ μ• λ  ν™•λ¥ :
P(μ„ νƒ μ• λ¨) = (1 - 1/N)^N

Nμ΄ ν΄ λ•:
lim (1 - 1/N)^N = 1/e β‰ 0.368 = 36.8%
Nβ†’β

κ²°λ΅ :
- μ•½ 63.2%κ°€ ν›λ ¨μ— μ‚¬μ©
- μ•½ 36.8%κ°€ OOB (ν…μ¤νΈμ©)
```

**μμ‹**:
```
μ›λ³Έ: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

Bootstrap Sample 1 (λ³µμ› μ¶”μ¶):
[2, 4, 4, 7, 9, 3, 1, 8, 4, 10]
       β†‘μ¤‘λ³µ

OOB Sample 1:
[5, 6] β† μ„ νƒ μ• λ μƒν”λ“¤

μ΄κ²ƒμΌλ΅ λ¨λΈ ν‰κ°€
```

### 4.4 μ¥λ‹¨μ 

**μ¥μ **:
```
β“ λ°μ΄ν„° ν™μ©λ„ λ†’μ
β“ μ‹ λΆ° κµ¬κ°„ μ¶”μ • κ°€λ¥
β“ μ‘μ€ λ°μ΄ν„°μ…‹μ— μ μ©
β“ λ¶„μ‚° μ¶”μ • μ°μ
β“ ν†µκ³„μ  μ‹ λΆ°λ„ λ†’μ
β“ Random Forest λ“±μ—μ„ μ‚¬μ©
```

**λ‹¨μ **:
```
β— κ³„μ‚° λΉ„μ© λ†’μ (Bλ² λ°λ³µ)
β— μ¤‘λ³µ μƒν”λ΅ μΈν• νΈν–¥
β— μ‹κ°„ μ†μ” νΌ
β— OOBκ°€ μ‘μ„ μ μμ (36.8%)
```

### 4.5 λ¶€νΈμ¤νΈλ© vs K-ν΄λ“ λΉ„κµ

| ν•­λ© | λ¶€νΈμ¤νΈλ© | K-ν΄λ“ |
|------|----------|--------|
| **μƒν”λ§** | λ³µμ› μ¶”μ¶ | λΉ„λ³µμ› λ¶„ν•  |
| **μ¤‘λ³µ** | μμ | μ—†μ |
| **ν…μ¤νΈ λΉ„μ¨** | 36.8% (OOB) | 1/K (μ: 20%) |
| **λ°λ³µ νμ** | Bλ² (100~1,000) | Kλ² (5~10) |
| **κ³„μ‚° λΉ„μ©** | λ†’μ | μ¤‘κ°„ |
| **μ μ©** | ν†µκ³„, μ•™μƒλΈ” | μΌλ° λ¨λΈ ν‰κ°€ |

### 4.6 .632 Bootstrap

**λ¬Έμ **: OOBκ°€ μ‘μ•„ νΈν–¥ κ°€λ¥

**ν•΄κ²°**: .632 κ°€μ¤‘ ν‰κ· 

```
μ„±λ¥_final = 0.632 Γ— μ„±λ¥_OOB + 0.368 Γ— μ„±λ¥_train

μ„¤λ…:
- 63.2%: OOB ν‰κ°€ κ°€μ¤‘μΉ
- 36.8%: ν›λ ¨ λ°μ΄ν„° κ°€μ¤‘μΉ

λ‚™κ΄€μ  νΈν–¥ κ°μ†
```

### 4.7 μμ‹

```
μ›λ³Έ λ°μ΄ν„°: 100κ°

λ¶€νΈμ¤νΈλ© (B=100):

λ°λ³µ 1:
- λ³µμ› μ¶”μ¶ β†’ ν›λ ¨ 100κ° (μΌλ¶€ μ¤‘λ³µ)
- OOB β†’ ν…μ¤νΈ μ•½ 37κ°
- μ •ν™•λ„: 0.83

λ°λ³µ 2:
- λ³µμ› μ¶”μ¶ β†’ ν›λ ¨ 100κ° (λ‹¤λ¥Έ μ΅°ν•©)
- OOB β†’ ν…μ¤νΈ μ•½ 35κ°
- μ •ν™•λ„: 0.85

...

λ°λ³µ 100:
- μ •ν™•λ„: 0.84

ν‰κ·  μ •ν™•λ„: 0.840
ν‘μ¤€νΈμ°¨: 0.018
95% μ‹ λΆ°κµ¬κ°„: [0.804, 0.876]
```

---

## 5. λ¬΄μ‘μ„ μ„λΈμƒν”λ§ (Random Subsampling)

### 5.1 μ •μ

**λ¬΄μ‘μ„ μ„λΈμƒν”λ§**: λ°μ΄ν„°λ¥Ό μ—¬λ¬ λ² λ¬΄μ‘μ„λ΅ λ¶„ν• ν•μ—¬ ν‰κ°€ (λΉ„λ³µμ› μ¶”μ¶)

### 5.2 λ°©λ²•

```
μ „μ²΄ λ°μ΄ν„°
    β†“
λ°λ³µ 1: λ¬΄μ‘μ„ 80:20 λ¶„ν• 
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚   ν›λ ¨ (80%)    β”‚ν…μ¤νΈ  β”‚ β†’ μ„±λ¥1
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”

λ°λ³µ 2: λ‹¤μ‹ λ¬΄μ‘μ„ 80:20 λ¶„ν• 
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚   ν›λ ¨ (80%)    β”‚ν…μ¤νΈ  β”‚ β†’ μ„±λ¥2
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”

λ°λ³µ 3: λ‹¤μ‹ λ¬΄μ‘μ„ 80:20 λ¶„ν• 
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚   ν›λ ¨ (80%)    β”‚ν…μ¤νΈ  β”‚ β†’ μ„±λ¥3
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”

...

λ°λ³µ N: λ‹¤μ‹ λ¬΄μ‘μ„ 80:20 λ¶„ν• 
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¬β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚   ν›λ ¨ (80%)    β”‚ν…μ¤νΈ  β”‚ β†’ μ„±λ¥N
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”΄β”€β”€β”€β”€β”€β”€β”€β”€β”

ν‰κ·  μ„±λ¥ = mean(μ„±λ¥1, ..., μ„±λ¥N)
```

**μ μ°¨**:
```
1. λ¶„ν•  λΉ„μ¨ κ²°μ • (μ: 80:20)
2. λ°λ³µ νμ N κ²°μ • (μ: 10~30)
3. for i in 1 to N:
   a. λ°μ΄ν„° μ„κΈ°
   b. ν›λ ¨:ν…μ¤νΈ λ¶„ν• 
   c. λ¨λΈ ν•™μµ
   d. ν…μ¤νΈ ν‰κ°€ β†’ μ„±λ¥_i
4. ν‰κ·  μ„±λ¥ κ³„μ‚°
```

### 5.3 νΉμ§•

**ν™€λ“μ•„μ›ƒκ³Όμ μ°¨μ΄**:
```
ν™€λ“μ•„μ›ƒ:
- 1λ²λ§ λ¶„ν• 
- λ¶„ν•  μ΄μ— λ”°λΌ κ²°κ³Ό λ³€λ™

λ¬΄μ‘μ„ μ„λΈμƒν”λ§:
- Nλ² λ¶„ν• 
- ν‰κ· μΌλ΅ μ•μ •μ  μ¶”μ •
```

**K-ν΄λ“μ™€μ μ°¨μ΄**:
```
K-ν΄λ“:
- λ¨λ“  λ°μ΄ν„°κ°€ μ •ν™•ν 1λ² ν…μ¤νΈ
- κ²ΉμΉμ§€ μ•λ” λ¶„ν• 

λ¬΄μ‘μ„ μ„λΈμƒν”λ§:
- μΌλ¶€ μƒν”μ΄ μ—¬λ¬ λ² ν…μ¤νΈλ  μ μμ
- μΌλ¶€ μƒν”μ΄ ν• λ²λ„ ν…μ¤νΈ μ• λ  μ μμ
- κ²ΉμΉλ” λ¶„ν•  κ°€λ¥
```

### 5.4 μ¥λ‹¨μ 

**μ¥μ **:
```
β“ ν™€λ“μ•„μ›ƒλ³΄λ‹¤ μ‹ λΆ°λ„ λ†’μ
β“ K-ν΄λ“λ³΄λ‹¤ μ μ—°ν•¨
β“ λ¶„ν•  λΉ„μ¨ μμ λ΅­κ² μ„ νƒ
β“ λ°λ³µ νμ μ΅°μ  κ°€λ¥
β“ κµ¬ν„ κ°„λ‹¨
```

**λ‹¨μ **:
```
β— K-ν΄λ“λ³΄λ‹¤ λ°μ΄ν„° ν™μ© λΉ„ν¨μ¨
β— μΌλ¶€ μƒν” λ―Έμ‚¬μ© κ°€λ¥
β— μΌλ¶€ μƒν” μ¤‘λ³µ ν…μ¤νΈ
β— K-ν΄λ“λ³΄λ‹¤ λ¶„μ‚° ν΄ μ μμ
```

### 5.5 Monte Carlo CV

**λ‹¤λ¥Έ μ΄λ¦„**: Monte Carlo Cross-Validation

**νΉμ§•**:
- λ¬΄μ‘μ„ μ„λΈμƒν”λ§μ λ‹¤λ¥Έ μ΄λ¦„
- ν†µκ³„ν•™μ—μ„ λ§μ΄ μ‚¬μ©
- λ¬ν…μΉ΄λ¥Όλ΅ μ‹λ®¬λ μ΄μ… λ°©λ²•λ΅ 

### 5.6 μμ‹

```
λ°μ΄ν„°: 1,000κ°
λ¶„ν• : 80:20
λ°λ³µ: 10ν

λ°λ³µ 1: λ¬΄μ‘μ„ λ¶„ν• 
- ν›λ ¨: 800κ°
- ν…μ¤νΈ: 200κ°
- μ •ν™•λ„: 0.85

λ°λ³µ 2: λ‹¤μ‹ λ¬΄μ‘μ„ λ¶„ν•  (λ‹¤λ¥Έ 800/200)
- μ •ν™•λ„: 0.87

...

λ°λ³µ 10:
- μ •ν™•λ„: 0.84

ν‰κ·  μ •ν™•λ„: 0.858
ν‘μ¤€νΈμ°¨: 0.012

μ£Όμ:
μΌλ¶€ μƒν”μ€ 10λ² μ¤‘ 3λ² ν…μ¤νΈλ  μ μμ
μΌλ¶€ μƒν”μ€ ν• λ²λ„ ν…μ¤νΈ μ• λ  μ μμ
```

---

## 6. μƒμ„Έ λΉ„κµ

### 6.1 μ „μ²΄ λΉ„κµν‘

| νΉμ„± | ν™€λ“μ•„μ›ƒ | K-ν΄λ“ | λ¶€νΈμ¤νΈλ© | λ¬΄μ‘μ„ μ„λΈμƒν”λ§ |
|------|---------|--------|----------|-----------------|
| **λ¶„ν•  νμ** | 1ν | Kν | Bν | Nν |
| **μƒν”λ§ λ°©μ‹** | λΉ„λ³µμ› | λΉ„λ³µμ› | λ³µμ› | λΉ„λ³µμ› |
| **λ°μ΄ν„° ν™μ©** | λ‚®μ (70-80%) | λ†’μ (100%) | λ†’μ (63.2% Γ— B) | μ¤‘κ°„ (80% Γ— N) |
| **λ¨λ“  μƒν” ν…μ¤νΈ** | μΌλ¶€λ§ | λ¨λ‘ 1λ²μ”© | ν‰κ·  36.8%μ”© | μΌλ¶€ μ—¬λ¬ λ² |
| **κ³„μ‚° λΉ„μ©** | β΅ λ§¤μ° λ‚®μ | μ¤‘κ°„ | λ†’μ | μ¤‘κ°„ |
| **μ‹ λΆ°λ„** | λ‚®μ | λ†’μ | λ§¤μ° λ†’μ | μ¤‘κ°„ |
| **λ¶„μ‚° μ¶”μ •** | λ¶κ°€ | κ°€λ¥ | μ°μ | κ°€λ¥ |
| **λ€μ©λ‰ λ°μ΄ν„°** | β… μ ν•© | λ³΄ν†µ | β λ¶€μ ν•© | λ³΄ν†µ |
| **μ‘μ€ λ°μ΄ν„°** | β λ¶€μ ν•© | β… μ ν•© | β… μ ν•© | λ³΄ν†µ |

### 6.2 μ‹κ°μ  λΉ„κµ

**ν™€λ“μ•„μ›ƒ**:
```
[β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–‘β–‘β–‘β–‘β–‘]
 ν›λ ¨ (80%)         ν…μ¤νΈ
 
 1ν ν‰κ°€
```

**5-Fold**:
```
λ°λ³µ1: [ν…][ν›][ν›][ν›][ν›]
λ°λ³µ2: [ν›][ν…][ν›][ν›][ν›]
λ°λ³µ3: [ν›][ν›][ν…][ν›][ν›]
λ°λ³µ4: [ν›][ν›][ν›][ν…][ν›]
λ°λ³µ5: [ν›][ν›][ν›][ν›][ν…]

λ¨λ“  λ°μ΄ν„°κ°€ μ •ν™•ν 1λ² ν…μ¤νΈ
5ν ν‰κ°€ β†’ ν‰κ· 
```

**λ¶€νΈμ¤νΈλ© (3ν)**:
```
μ›λ³Έ: [1][2][3][4][5][6][7][8][9][10]

μƒν”1: [1][3][3][5][7][7][9][4][2][8]
OOB1:  [6][10] β†’ ν…μ¤νΈ

μƒν”2: [2][4][4][6][1][9][3][5][8][8]
OOB2:  [7][10] β†’ ν…μ¤νΈ

μƒν”3: [5][1][3][9][2][4][6][7][7][10]
OOB3:  [8] β†’ ν…μ¤νΈ

λ³µμ› μ¶”μ¶, μ¤‘λ³µ κ°€λ¥
```

**λ¬΄μ‘μ„ μ„λΈμƒν”λ§ (3ν)**:
```
λ°λ³µ1: [β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–β–‘β–‘β–‘β–‘β–‘]
        ν›λ ¨             ν…μ¤νΈ

λ°λ³µ2: [β–β–β–β–β–β–β–β–‘β–‘β–‘β–‘β–‘β–β–β–β–β–β–β–β–β–β–β–β–β–]
        ν›λ ¨   ν…μ¤νΈ  ν›λ ¨

λ°λ³µ3: [β–β–β–β–β–β–β–β–β–β–β–‘β–‘β–‘β–‘β–‘β–β–β–β–β–β–β–β–β–β–β–]
        ν›λ ¨      ν…μ¤νΈ   ν›λ ¨

λ§¤λ² λ‹¤λ¥Έ λ¬΄μ‘μ„ λ¶„ν• 
μΌλ¶€ κ²ΉμΉ¨ κ°€λ¥
```

### 6.3 μμΉ μμ‹

**μ‹λ‚λ¦¬μ¤**: 100κ° λ°μ΄ν„°, λ¨λΈ μ •ν™•λ„ 85%

**ν™€λ“μ•„μ›ƒ (80:20)**:
```
- ν›λ ¨: 80κ°
- ν…μ¤νΈ: 20κ°
- ν‰κ°€ 1ν: 85%
- μ‹ λΆ°κµ¬κ°„: μ• μ μ—†μ
- μ‹κ°„: 1λ¶„
```

**5-Fold**:
```
- κ° Fold: 80κ° ν›λ ¨, 20κ° ν…μ¤νΈ
- ν‰κ°€ 5ν: [83%, 87%, 84%, 86%, 85%]
- ν‰κ· : 85%
- ν‘μ¤€νΈμ°¨: 1.4%
- μ‹ λΆ°κµ¬κ°„: [82.2%, 87.8%]
- μ‹κ°„: 5λ¶„
```

**λ¶€νΈμ¤νΈλ© (B=100)**:
```
- κ° λ°λ³µ: μ•½ 63κ° ν›λ ¨, 37κ° ν…μ¤νΈ
- ν‰κ°€ 100ν
- ν‰κ· : 84.5%
- ν‘μ¤€νΈμ°¨: 2.1%
- μ‹ λΆ°κµ¬κ°„: [80.3%, 88.7%]
- μ‹κ°„: 100λ¶„
```

**λ¬΄μ‘μ„ μ„λΈμƒν”λ§ (10ν, 80:20)**:
```
- κ° λ°λ³µ: 80κ° ν›λ ¨, 20κ° ν…μ¤νΈ
- ν‰κ°€ 10ν: [84%, 86%, 83%, 87%, 85%, ...]
- ν‰κ· : 85.2%
- ν‘μ¤€νΈμ°¨: 1.8%
- μ‹ λΆ°κµ¬κ°„: [81.6%, 88.8%]
- μ‹κ°„: 10λ¶„
```

### 6.4 μ–Έμ  λ¬΄μ—‡μ„ μ‚¬μ©ν• κΉ?

```
λ°μ΄ν„° ν¬κΈ°λ³„:

λ§¤μ° μ‘μ (n < 100):
β†’ LOOCV λλ” K-Fold (K=10)

μ‘μ (100 < n < 1,000):
β†’ K-Fold (K=5~10) λλ” λ¶€νΈμ¤νΈλ©

μ¤‘κ°„ (1K < n < 100K):
β†’ K-Fold (K=5) λλ” λ¬΄μ‘μ„ μ„λΈμƒν”λ§

νΌ (100K < n < 1M):
β†’ ν™€λ“μ•„μ›ƒ λλ” K-Fold (K=3)

λ§¤μ° νΌ (n > 1M):
β†’ ν™€λ“μ•„μ›ƒ (90:10 λλ” 95:5)
```

```
λ©μ λ³„:

λΉ λ¥Έ ν”„λ΅ν† νƒ€μ…:
β†’ ν™€λ“μ•„μ›ƒ

μ‹ λΆ°λ„ λ†’μ€ ν‰κ°€:
β†’ K-Fold

ν†µκ³„μ  μ¶”λ΅ , μ‹ λΆ°κµ¬κ°„:
β†’ λ¶€νΈμ¤νΈλ©

ν•μ΄νΌνλΌλ―Έν„° νλ‹:
β†’ K-Fold (GridSearchμ—μ„ μ‚¬μ©)

μ•™μƒλΈ” λ¨λΈ:
β†’ λ¶€νΈμ¤νΈλ© (Random Forest)

μµμΆ… λ¨λΈ ν‰κ°€:
β†’ λ³„λ„ ν…μ¤νΈ μ„ΈνΈ
```

---

## 7. μ„ νƒ κ°€μ΄λ“

### 7.1 μμ‚¬κ²°μ • ν”λ΅μ°μ°¨νΈ

```
μ‹μ‘
 β†“
λ°μ΄ν„° ν¬κΈ°λ”?
 β”β”€ λ§¤μ° νΌ (>100λ§)
 β”‚   β†’ ν™€λ“μ•„μ›ƒ β“
 β”‚
 β”β”€ νΌ (10λ§~100λ§)
 β”‚   β†’ ν™€λ“μ•„μ›ƒ λλ” 3-Fold
 β”‚
 β”β”€ μ¤‘κ°„ (1μ²~10λ§)
 β”‚   β†“
 β”‚   μ‹κ°„ μ—¬μ  μμ?
 β”‚   β”β”€ YES β†’ 5-Fold λλ” 10-Fold β“
 β”‚   β””β”€ NO β†’ ν™€λ“μ•„μ›ƒ λλ” 3-Fold
 β”‚
 β””β”€ μ‘μ (<1μ²)
     β†“
     λ§¤μ° μ‘μ (<100)?
     β”β”€ YES β†’ LOOCV β“
     β””β”€ NO β†’ 10-Fold β“
```

### 7.2 μƒν™©λ³„ μ¶”μ²

| μƒν™© | μ¶”μ² λ°©λ²• | μ΄μ  |
|------|----------|------|
| **λΉ λ¥Έ μ‹¤ν—** | ν™€λ“μ•„μ›ƒ | λΉ λ¦„ |
| **μµμΆ… ν‰κ°€** | λ³„λ„ ν…μ¤νΈ μ„ΈνΈ | νΈν–¥ μ—†μ |
| **μ‘μ€ λ°μ΄ν„°** | K-Fold (K=10) | λ°μ΄ν„° ν™μ© μµλ€ν™” |
| **λ¶κ· ν• λ°μ΄ν„°** | Stratified K-Fold | ν΄λμ¤ λΉ„μ¨ μ μ§€ |
| **ν•μ΄νΌνλΌλ―Έν„° νλ‹** | K-Fold (K=5) | κ· ν• |
| **ν†µκ³„μ  μ¶”λ΅ ** | λ¶€νΈμ¤νΈλ© | μ‹ λΆ°κµ¬κ°„ |
| **Random Forest** | OOB | λ‚΄μ¥ ν‰κ°€ |
| **μ‹κ³„μ—΄ λ°μ΄ν„°** | Time Series Split | μ‹κ°„ μμ„ μ μ§€ |

### 7.3 μ£Όμμ‚¬ν•­

**λ°μ΄ν„° λ„μ (Data Leakage) λ°©μ§€**:
```
β μλ»λ μμ„:
1. μ „μ²΄ λ°μ΄ν„° μ •κ·ν™”
2. ν›λ ¨/ν…μ¤νΈ λ¶„ν• 
β†’ ν…μ¤νΈ λ°μ΄ν„° μ •λ³΄κ°€ ν›λ ¨μ— μ‚¬μ©λ¨

β… μ¬λ°”λ¥Έ μμ„:
1. ν›λ ¨/ν…μ¤νΈ λ¶„ν• 
2. ν›λ ¨ λ°μ΄ν„°λ΅ μ •κ·ν™” ν•™μµ
3. ν›λ ¨ λ°μ΄ν„° μ •κ·ν™”
4. κ°™μ€ νλΌλ―Έν„°λ΅ ν…μ¤νΈ λ°μ΄ν„° μ •κ·ν™”
```

**ν…μ¤νΈ μ„ΈνΈ μ¤μ© λ°©μ§€**:
```
β μλ»λ μ‚¬μ©:
1. K-Foldλ΅ ν‰κ°€
2. ν•μ΄νΌνλΌλ―Έν„° μ΅°μ •
3. λ‹¤μ‹ K-Foldλ΅ ν‰κ°€
4. λ‹¤μ‹ ν•μ΄νΌνλΌλ―Έν„° μ΅°μ •
...
β†’ K-Fold μ„ΈνΈμ— κ³Όμ ν•©

β… μ¬λ°”λ¥Έ μ‚¬μ©:
1. λ°μ΄ν„°λ¥Ό ν›λ ¨+κ²€μ¦ / ν…μ¤νΈλ΅ λ¶„ν• 
2. ν›λ ¨+κ²€μ¦μ—μ„ K-Foldλ΅ ν•μ΄νΌνλΌλ―Έν„° νλ‹
3. μµμ  νλΌλ―Έν„°λ΅ μ „μ²΄ ν›λ ¨+κ²€μ¦μΌλ΅ ν•™μµ
4. ν…μ¤νΈ μ„ΈνΈλ΅ 1λ²λ§ μµμΆ… ν‰κ°€
```

---

## 8. Python κµ¬ν„

### 8.1 ν™€λ“μ•„μ›ƒ

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# λ°μ΄ν„° μ¤€λΉ„
X, y = load_data()  # μμ‹

# ν™€λ“μ•„μ›ƒ (80:20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # ν…μ¤νΈ 20%
    random_state=42,    # μ¬ν„μ„±
    stratify=y          # κ³„μΈµμ  λ¶„ν• 
)

# λ¨λΈ ν•™μµ
model = LogisticRegression()
model.fit(X_train, y_train)

# ν‰κ°€
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"μ •ν™•λ„: {accuracy:.3f}")
```

### 8.2 K-Fold

```python
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LogisticRegression
import numpy as np

# λ°μ΄ν„° μ¤€λΉ„
X, y = load_data()

# λ¨λΈ
model = LogisticRegression()

# 5-Fold κµμ°¨κ²€μ¦
cv = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')

# κ²°κ³Ό
print(f"κ° Fold μ •ν™•λ„: {scores}")
print(f"ν‰κ·  μ •ν™•λ„: {scores.mean():.3f}")
print(f"ν‘μ¤€νΈμ°¨: {scores.std():.3f}")
print(f"95% μ‹ λΆ°κµ¬κ°„: [{scores.mean()-1.96*scores.std():.3f}, "
      f"{scores.mean()+1.96*scores.std():.3f}]")
```

**μλ™ κµ¬ν„**:
```python
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score

# K-Fold μ„¤μ •
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

scores = []
for fold, (train_idx, test_idx) in enumerate(kfold.split(X)):
    # λ°μ΄ν„° λ¶„ν• 
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    # ν•™μµ
    model = LogisticRegression()
    model.fit(X_train, y_train)
    
    # ν‰κ°€
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    scores.append(accuracy)
    
    print(f"Fold {fold+1}: {accuracy:.3f}")

print(f"\nν‰κ·  μ •ν™•λ„: {np.mean(scores):.3f}")
```

### 8.3 Stratified K-Fold

```python
from sklearn.model_selection import StratifiedKFold

# λ¶κ· ν• λ°μ΄ν„°μ— μ ν•©
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')

print(f"Stratified ν‰κ·  μ •ν™•λ„: {scores.mean():.3f}")
```

### 8.4 λ¶€νΈμ¤νΈλ©

```python
import numpy as np
from sklearn.utils import resample
from sklearn.metrics import accuracy_score

def bootstrap_evaluation(X, y, model, n_iterations=100):
    """λ¶€νΈμ¤νΈλ© ν‰κ°€"""
    scores = []
    
    for i in range(n_iterations):
        # λ¶€νΈμ¤νΈλ© μƒν” (λ³µμ› μ¶”μ¶)
        X_train, y_train = resample(X, y, 
                                    n_samples=len(X),
                                    random_state=i)
        
        # OOB μƒν” (Out-of-Bag)
        # μ„ νƒ μ• λ μΈλ±μ¤ μ°ΎκΈ°
        train_indices = np.unique(
            [X.tolist().index(x.tolist()) for x in X_train]
        )
        oob_indices = np.setdiff1d(np.arange(len(X)), train_indices)
        
        if len(oob_indices) == 0:
            continue
            
        X_test = X[oob_indices]
        y_test = y[oob_indices]
        
        # ν•™μµ λ° ν‰κ°€
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        scores.append(accuracy)
    
    return np.array(scores)

# μ‚¬μ©
model = LogisticRegression()
scores = bootstrap_evaluation(X, y, model, n_iterations=100)

print(f"ν‰κ·  μ •ν™•λ„: {scores.mean():.3f}")
print(f"ν‘μ¤€νΈμ°¨: {scores.std():.3f}")
print(f"95% μ‹ λΆ°κµ¬κ°„: [{np.percentile(scores, 2.5):.3f}, "
      f"{np.percentile(scores, 97.5):.3f}]")
```

### 8.5 λ¬΄μ‘μ„ μ„λΈμƒν”λ§

```python
from sklearn.model_selection import ShuffleSplit

# λ¬΄μ‘μ„ μ„λΈμƒν”λ§ (10ν, 80:20)
cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)

scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')

print(f"ν‰κ·  μ •ν™•λ„: {scores.mean():.3f}")
print(f"ν‘μ¤€νΈμ°¨: {scores.std():.3f}")
```

**μλ™ κµ¬ν„**:
```python
def random_subsampling(X, y, model, n_iterations=10, test_size=0.2):
    """λ¬΄μ‘μ„ μ„λΈμƒν”λ§ ν‰κ°€"""
    scores = []
    
    for i in range(n_iterations):
        # λ¬΄μ‘μ„ λ¶„ν• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, 
            test_size=test_size,
            random_state=i  # λ§¤λ² λ‹¤λ¥Έ seed
        )
        
        # ν•™μµ λ° ν‰κ°€
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        scores.append(accuracy)
    
    return np.array(scores)

# μ‚¬μ©
scores = random_subsampling(X, y, model, n_iterations=10)
print(f"ν‰κ·  μ •ν™•λ„: {scores.mean():.3f}")
```

### 8.6 LOOCV

```python
from sklearn.model_selection import LeaveOneOut

# LOOCV
loo = LeaveOneOut()

# μ£Όμ: λ°μ΄ν„°κ°€ λ§μΌλ©΄ λ§¤μ° λλ¦Ό
scores = cross_val_score(model, X, y, cv=loo, scoring='accuracy')

print(f"ν‰κ·  μ •ν™•λ„: {scores.mean():.3f}")
print(f"μ΄ λ°λ³µ νμ: {len(scores)}")
```

### 8.7 μ‹¤μ „ νμ΄ν”„λΌμΈ

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_validate

# νμ΄ν”„λΌμΈ κµ¬μ„± (μ „μ²λ¦¬ + λ¨λΈ)
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression())
])

# κµμ°¨κ²€μ¦ (μ—¬λ¬ μ§€ν‘)
cv_results = cross_validate(
    pipeline, X, y,
    cv=5,
    scoring=['accuracy', 'precision', 'recall', 'f1'],
    return_train_score=True
)

# κ²°κ³Ό μ¶λ ¥
print(f"ν…μ¤νΈ μ •ν™•λ„: {cv_results['test_accuracy'].mean():.3f}")
print(f"ν…μ¤νΈ μ •λ°€λ„: {cv_results['test_precision'].mean():.3f}")
print(f"ν…μ¤νΈ μ¬ν„μ¨: {cv_results['test_recall'].mean():.3f}")
print(f"ν…μ¤νΈ F1: {cv_results['test_f1'].mean():.3f}")

# κ³Όμ ν•© ν™•μΈ
print(f"\nν›λ ¨ μ •ν™•λ„: {cv_results['train_accuracy'].mean():.3f}")
print(f"ν…μ¤νΈ μ •ν™•λ„: {cv_results['test_accuracy'].mean():.3f}")
print(f"μ°¨μ΄: {(cv_results['train_accuracy'].mean() - 
                cv_results['test_accuracy'].mean()):.3f}")
```

### 8.8 λΉ„κµ μ‹κ°ν™”

```python
import matplotlib.pyplot as plt
import pandas as pd

# μ—¬λ¬ λ°©λ²• λΉ„κµ
methods = {
    'Hold-out': train_test_split,
    '5-Fold': KFold(n_splits=5, shuffle=True, random_state=42),
    '10-Fold': KFold(n_splits=10, shuffle=True, random_state=42),
    'Bootstrap': None,  # λ³„λ„ ν•¨μ
    'Random Sub': ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)
}

results = {}

# ν™€λ“μ•„μ›ƒ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model.fit(X_train, y_train)
results['Hold-out'] = [accuracy_score(y_test, model.predict(X_test))]

# K-Foldλ“¤
for name, cv in [('5-Fold', methods['5-Fold']), 
                  ('10-Fold', methods['10-Fold']),
                  ('Random Sub', methods['Random Sub'])]:
    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    results[name] = scores

# λ¶€νΈμ¤νΈλ©
results['Bootstrap'] = bootstrap_evaluation(X, y, model, n_iterations=10)

# μ‹κ°ν™”
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Box plot
axes[0].boxplot(results.values(), labels=results.keys())
axes[0].set_ylabel('Accuracy')
axes[0].set_title('Model Evaluation Methods Comparison')
axes[0].grid(True, alpha=0.3)

# ν‰κ· κ³Ό ν‘μ¤€νΈμ°¨
means = [np.mean(v) for v in results.values()]
stds = [np.std(v) for v in results.values()]

axes[1].bar(results.keys(), means, yerr=stds, capsize=5, alpha=0.7)
axes[1].set_ylabel('Accuracy')
axes[1].set_title('Mean Accuracy with Std')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# μ”μ•½ ν…μ΄λΈ”
summary = pd.DataFrame({
    'Method': results.keys(),
    'Mean': means,
    'Std': stds,
    'Min': [np.min(v) for v in results.values()],
    'Max': [np.max(v) for v in results.values()]
})
print(summary)
```

---

## 9. λΉ…λ°μ΄ν„°λ¶„μ„κΈ°μ‚¬ μ‹ν— λ€λΉ„

### 9.1 ν•µμ‹¬ κ°λ… μ •λ¦¬

**ν™€λ“μ•„μ›ƒ**:
```
β“ 1λ² λ¶„ν• 
β“ λΉ λ¦„
β“ λΉ„λ³µμ› μ¶”μ¶
β“ μΌλ¶€ λ°μ΄ν„°λ§ μ‚¬μ©
β“ μ‹ λΆ°λ„ λ‚®μ
```

**K-Fold**:
```
β“ Kλ² λ¶„ν• 
β“ λ¨λ“  λ°μ΄ν„° 1λ²μ”© ν…μ¤νΈ
β“ λΉ„λ³µμ› μ¶”μ¶
β“ μ‹ λΆ°λ„ λ†’μ
β“ K=5 λλ” 10 λ§μ΄ μ‚¬μ©
```

**λ¶€νΈμ¤νΈλ©**:
```
β“ λ³µμ› μ¶”μ¶
β“ μ¤‘λ³µ ν—μ©
β“ OOB: μ•½ 36.8%
β“ μ‹ λΆ°κµ¬κ°„ μ¶”μ •
β“ Random Forestμ—μ„ μ‚¬μ©
```

**λ¬΄μ‘μ„ μ„λΈμƒν”λ§**:
```
β“ μ—¬λ¬ λ² λ¬΄μ‘μ„ λ¶„ν• 
β“ λΉ„λ³µμ› μ¶”μ¶
β“ ν™€λ“μ•„μ›ƒμ λ°λ³µ λ²„μ „
β“ μ μ—°ν• λΉ„μ¨ μ„ νƒ
```

### 9.2 μμƒ λ¬Έμ 

**λ¬Έμ  1**:
```
λ‹¤μ μ¤‘ λ³µμ› μ¶”μ¶ λ°©μ‹μ„ μ‚¬μ©ν•λ” κ²ƒμ€?

β‘  ν™€λ“μ•„μ›ƒ
β‘΅ K-ν΄λ“ κµμ°¨κ²€μ¦
β‘Ά λ¶€νΈμ¤νΈλ©
β‘£ λ¬΄μ‘μ„ μ„λΈμƒν”λ§

μ •λ‹µ: β‘Ά
```

**λ¬Έμ  2**:
```
λ°μ΄ν„°λ¥Ό Kκ°λ΅ λ‚λ„κ³ , κ°κ°μ„ ν• λ²μ”© ν…μ¤νΈ μ„ΈνΈλ΅
μ‚¬μ©ν•λ©° Kλ² ν‰κ°€ν•λ” λ°©λ²•μ€?

β‘  ν™€λ“μ•„μ›ƒ
β‘΅ K-ν΄λ“ κµμ°¨κ²€μ¦
β‘Ά λ¶€νΈμ¤νΈλ©
β‘£ LOOCV

μ •λ‹µ: β‘΅
```

**λ¬Έμ  3**:
```
λ¶€νΈμ¤νΈλ©μ—μ„ OOB(Out-of-Bag) μƒν”μ λΉ„μ¨μ€?

β‘  μ•½ 26.8%
β‘΅ μ•½ 36.8%
β‘Ά μ•½ 50%
β‘£ μ•½ 63.2%

μ •λ‹µ: β‘΅
```

**λ¬Έμ  4**:
```
κ°€μ¥ κ³„μ‚° λΉ„μ©μ΄ λ†’μ€ ν‰κ°€ λ°©λ²•μ€?

β‘  ν™€λ“μ•„μ›ƒ
β‘΅ 5-Fold
β‘Ά LOOCV
β‘£ λ¬΄μ‘μ„ μ„λΈμƒν”λ§ (10ν)

μ •λ‹µ: β‘Ά (Nλ² ν•™μµ, N=λ°μ΄ν„° κ°μ)
```

### 9.3 λΉ„κµν‘ μ•”κΈ°

| λ°©λ²• | λ¶„ν•  | λ³µμ› | λ°λ³µ | μ©λ„ |
|------|------|------|------|------|
| ν™€λ“μ•„μ›ƒ | 1ν | β— | 1ν | λΉ λ¥Έ ν‰κ°€ |
| K-Fold | Kν | β— | Kν | μΌλ° ν‰κ°€ |
| λ¶€νΈμ¤νΈλ© | Bν | β… | Bν | μ‹ λΆ°κµ¬κ°„ |
| λ¬΄μ‘μ„ | Nν | β— | Nν | μ μ—°ν• ν‰κ°€ |

---

## μ”μ•½

### ν•µμ‹¬ ν¬μΈνΈ

**μ–Έμ  λ¬΄μ—‡μ„ μ‚¬μ©ν• κΉ?**

```
λΉ λ¥Έ μ‹¤ν— β†’ ν™€λ“μ•„μ›ƒ
μ‘μ€ λ°μ΄ν„° β†’ K-Fold (K=10)
μ¤‘κ°„ λ°μ΄ν„° β†’ K-Fold (K=5)
ν° λ°μ΄ν„° β†’ ν™€λ“μ•„μ›ƒ λλ” 3-Fold
μ‹ λΆ°κµ¬κ°„ ν•„μ” β†’ λ¶€νΈμ¤νΈλ©
ν•μ΄νΌνλΌλ―Έν„° νλ‹ β†’ K-Fold
Random Forest β†’ λ¶€νΈμ¤νΈλ© (λ‚΄μ¥)
```

**κΈ°μ–µν•  ν•µμ‹¬ μμΉ**:
```
ν™€λ“μ•„μ›ƒ: 80:20 λλ” 70:30
K-Fold: K=5 λλ” K=10
λ¶€νΈμ¤νΈλ©: OOB 36.8%, B=100~1,000
λ¬΄μ‘μ„: 10~30ν λ°λ³µ
```

**κ°€μ¥ μ¤‘μ”ν• μ›μΉ™**:
```
β“ ν…μ¤νΈ λ°μ΄ν„°λ” ν•™μµμ— μ λ€ μ‚¬μ© κΈμ§€
β“ μ „μ²λ¦¬λ” λ¶„ν•  ν›„ μν–‰
β“ μµμΆ… ν‰κ°€λ” λ³„λ„ ν…μ¤νΈ μ„ΈνΈ
β“ μ‘μ€ λ°μ΄ν„°λ” K-Fold
β“ ν° λ°μ΄ν„°λ” ν™€λ“μ•„μ›ƒ
```

---

**μ‹ν— μ¤€λΉ„ ν™”μ΄ν…! π―**

κ° λ°©λ²•μ νΉμ§•κ³Ό μ μ© μƒν™©μ„ μ •ν™•ν μ΄ν•΄ν•λ©΄ μ¶©λ¶„ν•©λ‹λ‹¤!
