# 연관관계 분석 완벽 가이드

## 목차
1. [연관관계 개요](#1-연관관계-개요)
2. [양적 변수 간 연관관계 (상관분석)](#2-양적-변수-간-연관관계-상관분석)
3. [질적 변수 간 연관관계 (교차분석)](#3-질적-변수-간-연관관계-교차분석)
4. [연관규칙 분석](#4-연관규칙-분석)
5. [실전 예제](#5-실전-예제)

---

## 1. 연관관계 개요

### 1.1 연관관계란?

**연관관계(Association)**는 두 개 이상의 변수 간에 존재하는 관계를 의미합니다.

| 구분 | 설명 | 주요 방법 |
|------|------|----------|
| **양적 변수** | 연속형 수치 데이터 간의 관계 | 상관분석, 회귀분석 |
| **질적 변수** | 범주형 데이터 간의 관계 | 교차분석, 카이제곱 검정 |
| **혼합형** | 양적+질적 변수 | ANOVA, 점이연상관 |

### 1.2 연관관계의 특징

| 특징 | 설명 |
|------|------|
| **방향성** | 양의 관계, 음의 관계, 무관계 |
| **강도** | 약한 관계 ~ 강한 관계 |
| **선형성** | 선형 관계 vs 비선형 관계 |
| **인과성** | 연관 ≠ 인과 (상관관계가 인과관계를 의미하지 않음) |

---

## 2. 양적 변수 간 연관관계 (상관분석)

### 2.1 피어슨 상관계수 (Pearson Correlation Coefficient)

#### 이론

피어슨 상관계수 r은 두 연속형 변수 간의 **선형 관계**의 강도와 방향을 측정합니다.

**공식:**
```
r = Σ(xi - x̄)(yi - ȳ) / √[Σ(xi - x̄)² × Σ(yi - ȳ)²]

또는

r = Cov(X,Y) / (σx × σy)
```

**특징:**
- 범위: -1 ≤ r ≤ 1
- r = 1: 완전한 양의 선형관계
- r = -1: 완전한 음의 선형관계
- r = 0: 선형관계 없음

#### 해석 기준

| 상관계수 범위 | 해석 |
|--------------|------|
| 0.9 ≤ \|r\| ≤ 1.0 | 매우 강한 상관관계 |
| 0.7 ≤ \|r\| < 0.9 | 강한 상관관계 |
| 0.4 ≤ \|r\| < 0.7 | 중간 상관관계 |
| 0.2 ≤ \|r\| < 0.4 | 약한 상관관계 |
| 0.0 ≤ \|r\| < 0.2 | 매우 약한 상관관계 |

### 2.2 계산 예제 1: 피어슨 상관계수

**데이터:** 학생 5명의 수학 점수와 통계 점수

| 학생 | 수학(X) | 통계(Y) |
|------|---------|---------|
| A | 70 | 75 |
| B | 80 | 82 |
| C | 60 | 65 |
| D | 90 | 88 |
| E | 75 | 78 |

**Step 1: 평균 계산**
```
x̄ = (70 + 80 + 60 + 90 + 75) / 5 = 375 / 5 = 75
ȳ = (75 + 82 + 65 + 88 + 78) / 5 = 388 / 5 = 77.6
```

**Step 2: 편차 계산**

| 학생 | X | Y | (xi - x̄) | (yi - ȳ) | (xi - x̄)(yi - ȳ) | (xi - x̄)² | (yi - ȳ)² |
|------|---|---|----------|----------|------------------|-----------|-----------|
| A | 70 | 75 | -5 | -2.6 | 13 | 25 | 6.76 |
| B | 80 | 82 | 5 | 4.4 | 22 | 25 | 19.36 |
| C | 60 | 65 | -15 | -12.6 | 189 | 225 | 158.76 |
| D | 90 | 88 | 15 | 10.4 | 156 | 225 | 108.16 |
| E | 75 | 78 | 0 | 0.4 | 0 | 0 | 0.16 |
| **합계** | | | | | **380** | **500** | **293.2** |

**Step 3: 상관계수 계산**
```
r = Σ(xi - x̄)(yi - ȳ) / √[Σ(xi - x̄)² × Σ(yi - ȳ)²]
r = 380 / √(500 × 293.2)
r = 380 / √146,600
r = 380 / 382.88
r ≈ 0.992
```

**결과 해석:** r = 0.992로 **매우 강한 양의 선형관계**가 있습니다.

### 2.3 스피어만 순위 상관계수 (Spearman's Rank Correlation)

#### 이론

순서형 데이터 또는 정규성을 만족하지 않는 데이터에 사용하는 비모수적 방법입니다.

**공식:**
```
ρ = 1 - (6Σdi²) / (n(n² - 1))

di = 각 관측치의 순위 차이
n = 관측치 개수
```

### 2.4 계산 예제 2: 스피어만 상관계수

**데이터:** 5명 학생의 두 시험 순위

| 학생 | 시험1 순위(Ri) | 시험2 순위(Si) | di = Ri - Si | di² |
|------|---------------|---------------|--------------|-----|
| A | 1 | 2 | -1 | 1 |
| B | 2 | 1 | 1 | 1 |
| C | 3 | 4 | -1 | 1 |
| D | 4 | 3 | 1 | 1 |
| E | 5 | 5 | 0 | 0 |
| **합계** | | | | **4** |

**계산:**
```
ρ = 1 - (6 × 4) / (5 × (5² - 1))
ρ = 1 - 24 / (5 × 24)
ρ = 1 - 24 / 120
ρ = 1 - 0.2
ρ = 0.8
```

**결과 해석:** ρ = 0.8로 **강한 양의 순위 상관관계**가 있습니다.

---

## 3. 질적 변수 간 연관관계 (교차분석)

### 3.1 분할표 (Contingency Table)

질적 변수 간의 관계를 표로 나타낸 것입니다.

#### 2×2 분할표 예시

| | 성공 | 실패 | 합계 |
|---------|------|------|------|
| **치료군** | a | b | a+b |
| **대조군** | c | d | c+d |
| **합계** | a+c | b+d | n |

### 3.2 카이제곱 검정 (Chi-square Test)

#### 이론

두 범주형 변수 간의 독립성을 검정합니다.

**귀무가설(H₀):** 두 변수는 독립이다 (연관성 없음)  
**대립가설(H₁):** 두 변수는 독립이 아니다 (연관성 있음)

**검정통계량:**
```
χ² = Σ[(관측빈도 - 기대빈도)² / 기대빈도]
χ² = Σ[(Oi - Ei)² / Ei]

기대빈도 Ei = (행 합계 × 열 합계) / 전체 합계
```

**자유도:** df = (행 개수 - 1) × (열 개수 - 1)

### 3.3 계산 예제 3: 카이제곱 검정

**데이터:** 성별과 제품 선호도

**관측빈도 (O):**

| 성별 | 제품A | 제품B | 행 합계 |
|------|-------|-------|---------|
| **남성** | 30 | 20 | 50 |
| **여성** | 15 | 35 | 50 |
| **열 합계** | 45 | 55 | 100 |

**Step 1: 기대빈도 계산 (E)**

```
E(남성, 제품A) = (50 × 45) / 100 = 22.5
E(남성, 제품B) = (50 × 55) / 100 = 27.5
E(여성, 제품A) = (50 × 45) / 100 = 22.5
E(여성, 제품B) = (50 × 55) / 100 = 27.5
```

**기대빈도표:**

| 성별 | 제품A | 제품B |
|------|-------|-------|
| **남성** | 22.5 | 27.5 |
| **여성** | 22.5 | 27.5 |

**Step 2: 카이제곱 통계량 계산**

| 셀 | O | E | (O-E) | (O-E)² | (O-E)²/E |
|-----|---|---|-------|--------|----------|
| 남성,A | 30 | 22.5 | 7.5 | 56.25 | 2.50 |
| 남성,B | 20 | 27.5 | -7.5 | 56.25 | 2.05 |
| 여성,A | 15 | 22.5 | -7.5 | 56.25 | 2.50 |
| 여성,B | 35 | 27.5 | 7.5 | 56.25 | 2.05 |
| **합계** | | | | | **9.10** |

```
χ² = 2.50 + 2.05 + 2.50 + 2.05 = 9.10
```

**Step 3: 자유도와 임계값**
```
df = (2-1) × (2-1) = 1
α = 0.05일 때, χ²(1, 0.05) = 3.841
```

**결론:**
- χ² = 9.10 > 3.841 → 귀무가설 기각
- **성별과 제품 선호도 간에 유의한 연관관계가 있음**

### 3.4 연관성 측도

#### 파이 계수 (Phi Coefficient) - 2×2 표

```
φ = √(χ² / n)
```

위 예제에서:
```
φ = √(9.10 / 100) = √0.091 ≈ 0.302
```

#### 크래머의 V (Cramer's V) - 일반화

```
V = √[χ² / (n × min(r-1, c-1))]

r = 행 개수, c = 열 개수
```

**해석 기준:**

| V 값 | 연관성 강도 |
|------|-----------|
| 0.00 ~ 0.10 | 매우 약함 |
| 0.10 ~ 0.30 | 약함 |
| 0.30 ~ 0.50 | 중간 |
| 0.50 ~ | 강함 |

---

## 4. 연관규칙 분석

### 4.1 연관규칙이란?

**장바구니 분석(Market Basket Analysis)**에서 사용되는 기법으로, "X를 구매한 고객은 Y도 구매한다"는 규칙을 찾습니다.

**규칙 형태:** X → Y (X이면 Y)

### 4.2 주요 측도

#### 지지도 (Support)

전체 거래 중 X와 Y가 함께 나타나는 비율

```
Support(X → Y) = P(X ∩ Y) = |X ∩ Y| / |전체 거래|
```

#### 신뢰도 (Confidence)

X가 포함된 거래 중 Y도 포함된 거래의 비율

```
Confidence(X → Y) = P(Y|X) = P(X ∩ Y) / P(X)
                   = Support(X ∩ Y) / Support(X)
```

#### 향상도 (Lift)

X와 Y의 독립성 대비 실제 연관성의 비율

```
Lift(X → Y) = P(Y|X) / P(Y) = Confidence(X → Y) / Support(Y)
            = Support(X ∩ Y) / (Support(X) × Support(Y))
```

**해석:**
- Lift = 1: X와 Y는 독립
- Lift > 1: X와 Y는 양의 상관관계
- Lift < 1: X와 Y는 음의 상관관계

### 4.3 계산 예제 4: 연관규칙 분석

**데이터:** 10개 거래에서 구매한 상품

| 거래번호 | 구매 상품 |
|---------|-----------|
| T1 | 우유, 빵, 버터 |
| T2 | 우유, 빵 |
| T3 | 우유, 계란 |
| T4 | 빵, 버터 |
| T5 | 우유, 빵, 버터, 계란 |
| T6 | 빵, 계란 |
| T7 | 우유, 버터 |
| T8 | 우유, 빵, 버터 |
| T9 | 빵, 버터, 계란 |
| T10 | 우유, 계란 |

**Step 1: 상품별 출현 횟수**

| 상품 | 출현 거래 | 횟수 |
|------|----------|------|
| 우유 | T1, T2, T3, T5, T7, T8, T10 | 7 |
| 빵 | T1, T2, T4, T5, T6, T8, T9 | 7 |
| 버터 | T1, T4, T5, T7, T8, T9 | 6 |
| 계란 | T3, T5, T6, T9, T10 | 5 |

**Step 2: 규칙 "우유 → 빵" 분석**

```
전체 거래 수 = 10

우유가 포함된 거래: T1, T2, T3, T5, T7, T8, T10 → 7개
빵이 포함된 거래: T1, T2, T4, T5, T6, T8, T9 → 7개
우유와 빵이 함께 포함된 거래: T1, T2, T5, T8 → 4개
```

**지지도:**
```
Support(우유 → 빵) = 4/10 = 0.4 = 40%
```

**신뢰도:**
```
Confidence(우유 → 빵) = 4/7 ≈ 0.571 = 57.1%
```

**향상도:**
```
Support(빵) = 7/10 = 0.7
Lift(우유 → 빵) = 0.571 / 0.7 ≈ 0.816
```

**Step 3: 규칙 "빵 → 버터" 분석**

```
빵이 포함된 거래: 7개
버터가 포함된 거래: 6개
빵과 버터가 함께: T1, T4, T5, T8, T9 → 5개
```

**측도 계산:**

| 측도 | 계산 | 값 |
|------|------|-----|
| 지지도 | 5/10 | 0.5 (50%) |
| 신뢰도 | 5/7 | 0.714 (71.4%) |
| 향상도 | 0.714/0.6 | 1.19 |

**해석:** Lift = 1.19 > 1 이므로, 빵을 구매한 고객이 버터도 구매할 확률이 높습니다.

### 4.4 연관규칙 요약표

| 규칙 | 지지도 | 신뢰도 | 향상도 | 해석 |
|------|--------|--------|--------|------|
| 우유 → 빵 | 0.40 | 0.571 | 0.816 | 약한 연관성 |
| 빵 → 버터 | 0.50 | 0.714 | 1.19 | 양의 연관성 |
| 우유 → 버터 | 0.30 | 0.429 | 0.714 | 음의 연관성 |
| 빵 → 계란 | 0.30 | 0.429 | 0.857 | 약한 연관성 |

---

## 5. 실전 예제

### 5.1 종합 문제

**데이터:** 광고비와 매출액 (단위: 만원)

| 월 | 광고비(X) | 매출액(Y) |
|----|----------|----------|
| 1월 | 10 | 50 |
| 2월 | 15 | 65 |
| 3월 | 20 | 75 |
| 4월 | 25 | 90 |
| 5월 | 30 | 95 |

**문제:** 광고비와 매출액의 상관관계를 분석하시오.

### 5.2 풀이 과정

**Step 1: 기초 통계량**

```
n = 5
Σx = 10 + 15 + 20 + 25 + 30 = 100
Σy = 50 + 65 + 75 + 90 + 95 = 375
x̄ = 100/5 = 20
ȳ = 375/5 = 75
```

**Step 2: 계산표**

| 월 | X | Y | X² | Y² | XY |
|----|---|---|-----|-----|-----|
| 1월 | 10 | 50 | 100 | 2,500 | 500 |
| 2월 | 15 | 65 | 225 | 4,225 | 975 |
| 3월 | 20 | 75 | 400 | 5,625 | 1,500 |
| 4월 | 25 | 90 | 625 | 8,100 | 2,250 |
| 5월 | 30 | 95 | 900 | 9,025 | 2,850 |
| **합계** | **100** | **375** | **2,250** | **29,475** | **8,075** |

**Step 3: 상관계수 (공식 변형)**

```
r = [nΣXY - (ΣX)(ΣY)] / √{[nΣX² - (ΣX)²][nΣY² - (ΣY)²]}

분자 = 5(8,075) - (100)(375)
     = 40,375 - 37,500
     = 2,875

분모1 = 5(2,250) - (100)²
      = 11,250 - 10,000
      = 1,250

분모2 = 5(29,475) - (375)²
      = 147,375 - 140,625
      = 6,750

분모 = √(1,250 × 6,750)
     = √8,437,500
     ≈ 2,905

r = 2,875 / 2,905 ≈ 0.990
```

**결과:** r = 0.990으로 **광고비와 매출액 간에 매우 강한 양의 선형 상관관계**가 있습니다.

### 5.3 결정계수 (R²)

```
R² = r² = (0.990)² = 0.980 = 98.0%
```

**해석:** 매출액 변동의 98%가 광고비로 설명됩니다.

---

## 6. Python 실습 코드

### 6.1 피어슨 상관계수

```python
import numpy as np
import pandas as pd
from scipy import stats

# 데이터
math_scores = [70, 80, 60, 90, 75]
stat_scores = [75, 82, 65, 88, 78]

# 방법 1: numpy
correlation = np.corrcoef(math_scores, stat_scores)[0, 1]
print(f"상관계수 (numpy): {correlation:.4f}")

# 방법 2: scipy
r, p_value = stats.pearsonr(math_scores, stat_scores)
print(f"상관계수: {r:.4f}")
print(f"p-value: {p_value:.4f}")

# 방법 3: pandas
df = pd.DataFrame({'수학': math_scores, '통계': stat_scores})
print(df.corr())
```

### 6.2 스피어만 상관계수

```python
from scipy.stats import spearmanr

# 데이터
rank1 = [1, 2, 3, 4, 5]
rank2 = [2, 1, 4, 3, 5]

# 계산
rho, p_value = spearmanr(rank1, rank2)
print(f"스피어만 상관계수: {rho:.4f}")
print(f"p-value: {p_value:.4f}")
```

### 6.3 카이제곱 검정

```python
from scipy.stats import chi2_contingency
import numpy as np

# 분할표
observed = np.array([[30, 20],
                     [15, 35]])

# 카이제곱 검정
chi2, p_value, dof, expected = chi2_contingency(observed)

print(f"카이제곱 통계량: {chi2:.4f}")
print(f"p-value: {p_value:.4f}")
print(f"자유도: {dof}")
print(f"\n기대빈도:\n{expected}")

# 크래머의 V
n = observed.sum()
min_dim = min(observed.shape[0], observed.shape[1]) - 1
cramers_v = np.sqrt(chi2 / (n * min_dim))
print(f"크래머의 V: {cramers_v:.4f}")
```

### 6.4 연관규칙 분석 (mlxtend 사용)

```python
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules

# 거래 데이터
transactions = [
    ['우유', '빵', '버터'],
    ['우유', '빵'],
    ['우유', '계란'],
    ['빵', '버터'],
    ['우유', '빵', '버터', '계란'],
    ['빵', '계란'],
    ['우유', '버터'],
    ['우유', '빵', '버터'],
    ['빵', '버터', '계란'],
    ['우유', '계란']
]

# One-hot encoding
from mlxtend.preprocessing import TransactionEncoder
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df = pd.DataFrame(te_ary, columns=te.columns_)

# 빈발 항목집합 찾기
frequent_itemsets = apriori(df, min_support=0.3, use_colnames=True)
print("빈발 항목집합:")
print(frequent_itemsets)

# 연관규칙 생성
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.5)
print("\n연관규칙:")
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])
```

---

## 7. 빅데이터분석기사 시험 대비 핵심 정리

### 7.1 주요 공식 정리

| 분석 방법 | 공식 | 사용 조건 |
|----------|------|----------|
| 피어슨 상관계수 | r = Cov(X,Y) / (σx·σy) | 연속형, 정규성, 선형관계 |
| 스피어만 상관계수 | ρ = 1 - 6Σdi²/n(n²-1) | 순서형, 비정규성 |
| 카이제곱 검정 | χ² = Σ(O-E)²/E | 범주형, 기대빈도≥5 |
| 지지도 | P(X∩Y) | 연관규칙 |
| 신뢰도 | P(X∩Y)/P(X) | 연관규칙 |
| 향상도 | P(X∩Y)/(P(X)·P(Y)) | 연관규칙 |

### 7.2 시험 출제 패턴

1. **상관분석 계산** (고빈도)
   - 피어슨 상관계수 손계산
   - 결정계수 해석
   - 산점도 해석

2. **카이제곱 검정** (고빈도)
   - 기대빈도 계산
   - 검정통계량 계산
   - 독립성 검정

3. **연관규칙** (중빈도)
   - 지지도/신뢰도/향상도 계산
   - Apriori 알고리즘 이해

### 7.3 주의사항

| 구분 | 주의사항 |
|------|----------|
| **상관분석** | 상관 ≠ 인과, 이상치 영향 큼, 비선형 관계 감지 불가 |
| **카이제곱** | 기대빈도 < 5이면 Fisher 검정, 샘플 크기 영향 |
| **연관규칙** | 지지도 낮으면 우연, 신뢰도만 보면 오류 가능 |

---

## 8. 참고자료

### 8.1 추가 학습 자료

- 공분산(Covariance): 상관계수의 기초 개념
- 편상관(Partial Correlation): 제3의 변수 통제
- 다중공선성(Multicollinearity): 회귀분석 시 문제
- FP-Growth: Apriori의 개선 알고리즘

### 8.2 관련 통계량

| 통계량 | 설명 | 범위 |
|--------|------|------|
| 공분산 | 두 변수의 선형 관계 | -∞ ~ +∞ |
| 상관계수 | 표준화된 공분산 | -1 ~ +1 |
| 결정계수 | 설명력 | 0 ~ 1 |
| 카이제곱 | 독립성 검정 | 0 ~ +∞ |

---

## 요약

### 핵심 체크리스트

- [ ] 피어슨 상관계수 계산 및 해석
- [ ] 스피어만 상관계수 이해
- [ ] 카이제곱 검정 과정 숙지
- [ ] 기대빈도 계산 방법
- [ ] 연관규칙 3대 측도 계산
- [ ] 향상도 해석 (Lift > 1, = 1, < 1)
- [ ] Python 라이브러리 활용

### 실전 문제 풀이 팁

1. **상관계수 문제**: 표를 그려서 체계적으로 계산
2. **카이제곱 문제**: 기대빈도 먼저 정확히 구하기
3. **연관규칙 문제**: 지지도 → 신뢰도 → 향상도 순서로

---

**작성일:** 2026년 1월  
**용도:** 빅데이터분석기사 시험 대비 연관관계 분석 완벽 가이드
