# 유의수준 vs 유의확률

## 목차
1. [핵심 개념 비교](#핵심-개념-비교)
2. [유의수준 (α)](#유의수준-α)
3. [유의확률 (p-value)](#유의확률-p-value)
4. [둘의 차이와 관계](#둘의-차이와-관계)
5. [의사결정 규칙](#의사결정-규칙)
6. [계산 예시](#계산-예시)
7. [해석 방법](#해석-방법)
8. [흔한 오해](#흔한-오해)
9. [실전 예제](#실전-예제)
10. [시험 대비 핵심](#시험-대비-핵심)

---

## 핵심 개념 비교

### 한눈에 보는 차이

| 구분 | 유의수준 (α) | 유의확률 (p-value) |
|------|-------------|-------------------|
| **영어** | Significance Level | p-value, Probability value |
| **기호** | α (알파) | p |
| **정의** | 제1종 오류의 최대 허용 확률 | H₀ 하에서 관찰된 결과(또는 더 극단적)가 나올 확률 |
| **시점** | **검정 전** 설정 | **검정 후** 계산 |
| **성격** | 주관적 기준 | 객관적 산출 |
| **값** | 고정값 (보통 0.05) | 데이터 의존 |
| **역할** | 판단 기준선 | 증거의 강도 |
| **의미** | "이 정도 위험은 감수" | "이 결과가 얼마나 희귀한가" |

---

## 유의수준 (α)

### 정의

```
유의수준 (α) = 제1종 오류를 범할 최대 허용 확률

제1종 오류 (Type I Error):
H₀가 참인데 잘못 기각하는 오류
```

### 핵심 특징

#### ✅ 1. **검정 전에 미리 설정**

```
연구 설계 단계에서 결정
데이터 수집 전에 확정
```

#### ✅ 2. **연구자가 선택**

일반적인 기준:
- **α = 0.05 (5%)**: 일반적 연구
- **α = 0.01 (1%)**: 엄격한 기준 (의학, 약학)
- **α = 0.10 (10%)**: 탐색적 연구

#### ✅ 3. **고정값**

```
데이터와 무관하게 고정
실험 전체에서 일관성 유지
```

### 의미와 해석

#### α = 0.05의 의미

```
"귀무가설이 참일 때,
 잘못 기각할 확률을 5% 이하로 제한한다"

= 100번 검정 중 5번까지는 오류 감수
= 95% 신뢰수준
```

#### 오류와의 관계

```
α ↓ (엄격)  →  제1종 오류 ↓  BUT  제2종 오류 ↑
α ↑ (완화)  →  제1종 오류 ↑  BUT  제2종 오류 ↓

trade-off 관계
```

### 시각화

```
         기각역                채택역
    |-------------|---------------------------|
    0            α                           1
              (0.05)

α 기준으로 영역 구분
```

### 분야별 유의수준

| 분야 | 일반적 α | 이유 |
|------|---------|------|
| **사회과학** | 0.05 | 표준 |
| **의학 임상** | 0.01 | 생명 관련, 엄격 |
| **입자물리학** | 0.001 또는 5σ | 극도로 엄격 |
| **탐색 연구** | 0.10 | 가설 생성 목적 |
| **품질관리** | 0.05~0.10 | 실용성 고려 |

---

## 유의확률 (p-value)

### 정의

```
p-value = H₀가 참이라고 가정할 때,
          관찰된 통계량(또는 더 극단적인 값)이
          나올 확률
```

### 핵심 특징

#### ✅ 1. **검정 후에 계산**

```
데이터 수집 후
통계량 계산 후
확률 산출
```

#### ✅ 2. **확률값 (0~1)**

```
0 ≤ p-value ≤ 1

p → 0: 관찰된 결과가 매우 희귀
p → 1: 관찰된 결과가 흔함
```

#### ✅ 3. **데이터 의존**

```
샘플마다 다름
통계량의 함수
```

### 의미와 해석

#### p = 0.03의 의미

```
"귀무가설이 참이라면,
 우리가 관찰한 결과(또는 더 극단적인 결과)가
 나올 확률이 3%이다"

→ 매우 희귀한 사건 발생
→ H₀가 의심스러움
→ H₀와 데이터가 불일치
```

#### ⚠️ p-value가 **아닌** 것

❌ **H₀가 참일 확률 아님**
```
p-value는 P(Data | H₀)
H₀의 확률 P(H₀ | Data)가 아님!
```

❌ **효과 크기 아님**
```
작은 p-value ≠ 큰 효과
큰 샘플에서는 작은 효과도 유의할 수 있음
```

❌ **연구의 중요성 아님**
```
통계적 유의성 ≠ 실질적 의미
```

### p-value 크기별 해석

| p-value 범위 | 표현 | 증거 강도 | 기호 |
|-------------|------|----------|------|
| **p < 0.001** | 매우 매우 유의 | 매우 강한 증거 | *** |
| **0.001 ≤ p < 0.01** | 매우 유의 | 강한 증거 | ** |
| **0.01 ≤ p < 0.05** | 유의함 | 중간 증거 | * |
| **0.05 ≤ p < 0.10** | 경계선 | 약한 증거 | † |
| **p ≥ 0.10** | 유의하지 않음 | 증거 없음 | n.s. |

### 계산 방법

#### 양측검정 (Two-tailed)

```
p-value = 2 × P(|통계량| ≥ |관찰값|)

양쪽 꼬리 모두 고려
```

#### 단측검정 (One-tailed)

**우측 검정**
```
p-value = P(통계량 ≥ 관찰값)
```

**좌측 검정**
```
p-value = P(통계량 ≤ 관찰값)
```

**관계**
```
p_단측 = p_양측 / 2
```

---

## 둘의 차이와 관계

### 시간 순서

```
1. 연구 설계
   ↓
2. 유의수준(α) 설정  ← 검정 전
   ↓
3. 데이터 수집
   ↓
4. 통계량 계산
   ↓
5. p-value 계산  ← 검정 후
   ↓
6. α와 p 비교
   ↓
7. 의사결정
```

### 역할 비교

#### 유의수준 (α): **기준선**

```
"이 선을 넘으면 기각한다"

판사의 유죄 판단 기준과 유사
```

#### 유의확률 (p): **증거**

```
"증거가 얼마나 강한가"

검사가 제시하는 증거의 강도와 유사
```

### 상호작용

```
┌─────────────┐
│ α = 0.05    │  ← 미리 정한 기준
└─────────────┘
       ↓
┌─────────────┐
│ p = 0.03    │  ← 계산된 증거
└─────────────┘
       ↓
┌─────────────┐
│ p < α       │  ← 비교
└─────────────┘
       ↓
┌─────────────┐
│ H₀ 기각     │  ← 결론
└─────────────┘
```

---

## 의사결정 규칙

### 기본 규칙

```
p-value ≤ α  →  H₀ 기각 (유의함, Reject)
p-value > α  →  H₀ 채택 (유의하지 않음, Fail to reject)
```

### 시각적 표현

```
                α = 0.05
                    ↓
    |---------------|---------------------|
    0              0.05                  1
    
p = 0.03  →  기각역  →  H₀ 기각 ✓
p = 0.12  →  채택역  →  H₀채택
```

### 구체적 예시

#### 예시 1: 명확한 기각

```
α = 0.05
p = 0.001

p (0.001) < α (0.05)
→ H₀ 기각
→ "통계적으로 유의함"
→ "효과가 있다"
```

#### 예시 2: 명확한 채택

```
α = 0.05
p = 0.23

p (0.23) > α (0.05)
→ H₀ 채택 (기각 실패)
→ "통계적으로 유의하지 않음"
→ "효과가 있다는 증거 부족"
```

#### 예시 3: 경계선

```
α = 0.05
p = 0.052

p (0.052) > α (0.05)
→ 기술적으로는 채택
→ 하지만 거의 경계선
→ 표본 크기 늘리면 유의할 가능성
```

### 양측검정 vs 단측검정

```
관찰된 통계량: t = 2.1, df = 20

양측검정:
p_양측 = 0.048
α = 0.05
→ p < α → 기각 ✓

단측검정:
p_단측 = 0.024 (= 0.048/2)
α = 0.05
→ p < α → 기각 ✓

더 엄격한 기준:
α = 0.01
양측: p(0.048) > α(0.01) → 채택
단측: p(0.024) > α(0.01) → 채택
```

---

## 계산 예시

### 예제 1: 단일표본 t-검정

#### 문제 설정

```
새로운 학습법의 효과 검정

H₀: μ = 70 (기존 방법과 같음)
H₁: μ > 70 (새 방법이 더 좋음)

유의수준: α = 0.05
```

#### 데이터

```python
import numpy as np
from scipy import stats

# 데이터
sample = [75, 78, 72, 80, 76, 74, 79, 73, 77, 81]
mu_0 = 70
alpha = 0.05

print(f"샘플 크기: {len(sample)}")
print(f"샘플 평균: {np.mean(sample):.2f}")
print(f"샘플 표준편차: {np.std(sample, ddof=1):.2f}")
```

**출력:**
```
샘플 크기: 10
샘플 평균: 76.50
샘플 표준편차: 3.03
```

#### t-검정 수행

```python
# t-검정 (단측, 우측)
t_stat, p_value = stats.ttest_1samp(sample, mu_0, alternative='greater')

print(f"\n=== 검정 결과 ===")
print(f"유의수준 α: {alpha}")
print(f"t-통계량: {t_stat:.4f}")
print(f"자유도: {len(sample)-1}")
print(f"p-value: {p_value:.4f}")

# 임계값
df = len(sample) - 1
t_critical = stats.t.ppf(1-alpha, df)
print(f"임계값 (α={alpha}): {t_critical:.4f}")
```

**출력:**
```
=== 검정 결과 ===
유의수준 α: 0.05
t-통계량: 6.7868
자유도: 9
p-value: 0.0000
임계값 (α=0.05): 1.8331
```

#### 의사결정

```python
print(f"\n=== 의사결정 ===")
print(f"1. p-value 방법:")
print(f"   p-value ({p_value:.4f}) < α ({alpha})")
print(f"   → H₀ 기각")

print(f"\n2. 임계값 방법:")
print(f"   t-통계량 ({t_stat:.4f}) > 임계값 ({t_critical:.4f})")
print(f"   → H₀ 기각")

print(f"\n결론:")
print(f"새로운 학습법은 통계적으로 유의한 효과가 있다")
print(f"(유의수준 5%에서)")
```

**출력:**
```
=== 의사결정 ===
1. p-value 방법:
   p-value (0.0000) < α (0.05)
   → H₀ 기각

2. 임계값 방법:
   t-통계량 (6.7868) > 임계값 (1.8331)
   → H₀ 기각

결론:
새로운 학습법은 통계적으로 유의한 효과가 있다
(유의수준 5%에서)
```

---

### 예제 2: 독립표본 t-검정

#### 문제 설정

```
남녀 평균 키 차이 검정

H₀: μ_남 = μ_여 (차이 없음)
H₁: μ_남 ≠ μ_여 (차이 있음)

유의수준: α = 0.05 (양측검정)
```

#### 데이터 및 검정

```python
import numpy as np
from scipy import stats

# 데이터
male = [170, 175, 168, 172, 180, 165, 177, 173, 169, 174]
female = [160, 158, 165, 162, 159, 163, 161, 157, 164, 160]

alpha = 0.05

print(f"=== 기술통계 ===")
print(f"남성 평균: {np.mean(male):.2f} cm")
print(f"여성 평균: {np.mean(female):.2f} cm")
print(f"차이: {np.mean(male) - np.mean(female):.2f} cm")

# 독립표본 t-검정 (양측)
t_stat, p_value = stats.ttest_ind(male, female)

print(f"\n=== 검정 결과 ===")
print(f"유의수준 α: {alpha}")
print(f"t-통계량: {t_stat:.4f}")
print(f"p-value (양측): {p_value:.4f}")

# 의사결정
print(f"\n=== 의사결정 ===")
if p_value < alpha:
    print(f"p-value ({p_value:.4f}) < α ({alpha})")
    print(f"→ H₀ 기각")
    print(f"→ 남녀 평균 키 차이가 통계적으로 유의함")
else:
    print(f"p-value ({p_value:.4f}) > α ({alpha})")
    print(f"→ H₀채택")
    print(f"→ 남녀 평균 키 차이가 통계적으로 유의하지 않음")

# 효과크기 (Cohen's d)
pooled_std = np.sqrt(((len(male)-1)*np.var(male, ddof=1) + 
                       (len(female)-1)*np.var(female, ddof=1)) / 
                      (len(male) + len(female) - 2))
cohens_d = (np.mean(male) - np.mean(female)) / pooled_std

print(f"\n=== 효과크기 ===")
print(f"Cohen's d: {cohens_d:.4f}")
if abs(cohens_d) < 0.2:
    print("→ 작은 효과")
elif abs(cohens_d) < 0.5:
    print("→ 중간 효과")
else:
    print("→ 큰 효과")
```

**출력:**
```
=== 기술통계 ===
남성 평균: 172.30 cm
여성 평균: 160.90 cm
차이: 11.40 cm

=== 검정 결과 ===
유의수준 α: 0.05
t-통계량: 7.4523
p-value (양측): 0.0000

=== 의사결정 ===
p-value (0.0000) < α (0.05)
→ H₀ 기각
→ 남녀 평균 키 차이가 통계적으로 유의함

=== 효과크기 ===
Cohen's d: 3.3328
→ 큰 효과
```

---

### 예제 3: 카이제곱 검정

#### 문제 설정

```
교육 수준과 투표 참여의 독립성 검정

H₀: 교육 수준과 투표 참여는 독립이다
H₁: 교육 수준과 투표 참여는 독립이 아니다

유의수준: α = 0.05
```

#### 데이터 및 검정

```python
import numpy as np
from scipy.stats import chi2_contingency

# 분할표
data = np.array([
    [30, 10],  # 고졸: 투표함, 안함
    [45, 15],  # 대졸
    [25, 5]    # 대학원졸
])

alpha = 0.05

print("=== 관찰 빈도 ===")
print("            투표함  안함")
print(f"고졸        {data[0,0]:3d}   {data[0,1]:3d}")
print(f"대졸        {data[1,0]:3d}   {data[1,1]:3d}")
print(f"대학원졸    {data[2,0]:3d}   {data[2,1]:3d}")

# 카이제곱 검정
chi2_stat, p_value, df, expected = chi2_contingency(data)

print(f"\n=== 검정 결과 ===")
print(f"유의수준 α: {alpha}")
print(f"χ² 통계량: {chi2_stat:.4f}")
print(f"자유도: {df}")
print(f"p-value: {p_value:.4f}")

print(f"\n=== 기대 빈도 ===")
print("            투표함  안함")
for i, label in enumerate(['고졸', '대졸', '대학원졸']):
    print(f"{label:8s}    {expected[i,0]:5.2f} {expected[i,1]:5.2f}")

# 의사결정
print(f"\n=== 의사결정 ===")
if p_value < alpha:
    print(f"p-value ({p_value:.4f}) < α ({alpha})")
    print(f"→ H₀ 기각")
    print(f"→ 교육 수준과 투표 참여는 독립이 아니다")
else:
    print(f"p-value ({p_value:.4f}) > α ({alpha})")
    print(f"→ H₀ 채택")
    print(f"→ 교육 수준과 투표 참여는 독립이다")
```

**출력 예시:**
```
=== 관찰 빈도 ===
            투표함  안함
고졸         30    10
대졸         45    15
대학원졸     25     5

=== 검정 결과 ===
유의수준 α: 0.05
χ² 통계량: 0.4545
자유도: 2
p-value: 0.7967

=== 기대 빈도 ===
            투표함  안함
고졸        30.77  9.23
대졸        46.15 13.85
대학원졸    23.08  6.92

=== 의사결정 ===
p-value (0.7967) > α (0.05)
→ H₀ 채택
→ 교육 수준과 투표 참여는 독립이다
```

---

## 해석 방법

### p-value 해석 가이드

#### 1. 절대값 해석

| p-value | 해석 | 행동 |
|---------|------|------|
| **p < 0.001** | 극히 강한 증거 | 확실히 기각 |
| **0.001 ≤ p < 0.01** | 강한 증거 | 기각 |
| **0.01 ≤ p < 0.05** | 중간 증거 | 기각 (주의) |
| **0.05 ≤ p < 0.10** | 약한 증거 | 추가 연구 |
| **p ≥ 0.10** | 증거 없음 | 채택 |

#### 2. 맥락 고려 해석

```
p = 0.04인 경우:

상황 1: 샘플 크기 10,000
→ 통계적 유의 ✓
→ 하지만 효과 크기 매우 작을 수 있음
→ 실질적 의미 재고

상황 2: 샘플 크기 20
→ 통계적 유의 ✓
→ 중간~큰 효과 크기 가능
→ 의미있는 결과
```

#### 3. 문장으로 표현

```
✅ 올바른 표현:
"p = 0.03이므로 유의수준 5%에서 통계적으로 유의하다"
"p < 0.05로 H₀를 기각한다"
"관찰된 차이는 우연으로 보기 어렵다 (p = 0.03)"

❌ 잘못된 표현:
"p = 0.03이므로 H₀가 참일 확률이 3%"
"p = 0.03이므로 효과가 크다"
"p = 0.03이므로 연구가 중요하다"
```

### 유의수준 선택 가이드

#### 상황별 선택

```
α = 0.10 사용:
- 탐색적 연구
- 파일럿 스터디
- 가설 생성 목적
- 보수적일 필요 없는 경우

α = 0.05 사용:
- 일반적인 학술 연구
- 표준 실험
- 대부분의 상황

α = 0.01 사용:
- 의학 임상시험
- 중요한 정책 결정
- 엄격한 증거 필요
- 제1종 오류 비용 높음

α = 0.001 사용:
- 입자물리학
- 극도로 엄격한 기준
- 역사적 발견
```

#### 오류 비용 고려

```
제1종 오류 비용 > 제2종 오류 비용
→ 낮은 α (0.01)
예: 신약 부작용 검사

제1종 오류 비용 < 제2종 오류 비용
→ 높은 α (0.10)
예: 초기 스크리닝

비슷한 경우
→ α = 0.05 (표준)
```

---

## 흔한 오해

### 오해 1: p-value = H₀가 참일 확률

#### ❌ 잘못된 이해

```
"p = 0.03이므로 귀무가설이 참일 확률이 3%이다"
```

#### ✅ 올바른 이해

```
"귀무가설이 참이라고 가정할 때,
 이런 극단적 결과가 나올 확률이 3%이다"

p-value = P(Data | H₀)
H₀의 확률 P(H₀ | Data)가 아님!

베이즈 정리를 통해 변환해야 함
```

#### 예시

```
예: 범죄 재판

p-value:
"피고가 무죄라면, 이런 증거가 나올 확률"

≠ "이런 증거가 있을 때, 피고가 무죄일 확률"
```

---

### 오해 2: p-value = 효과 크기

#### ❌ 잘못된 이해

```
"p = 0.001이 p = 0.04보다 효과가 크다"
"p가 작을수록 중요한 결과"
```

#### ✅ 올바른 이해

```
p-value는 통계적 유의성 (샘플 크기 영향)
효과 크기는 별도 측정 필요

작은 p-value ≠ 큰 효과

큰 샘플: 작은 효과도 p < 0.001
작은 샘플: 큰 효과도 p > 0.05 가능
```

#### 예시

```python
# 시나리오 1: 큰 샘플, 작은 효과
n1 = 10000
mean_diff = 0.5  # 작은 차이
p_value = 0.0001  # 매우 유의
효과크기 = 0.1  # 작은 효과

# 시나리오 2: 작은 샘플, 큰 효과
n2 = 20
mean_diff = 5.0  # 큰 차이
p_value = 0.07  # 비유의
효과크기 = 0.8  # 큰 효과

→ p-value만으로 효과 크기 판단 불가!
```

---

### 오해 3: α = 내 결론이 틀릴 확률

#### ❌ 잘못된 이해

```
"α = 0.05이므로 내 결과가 틀릴 확률 5%"
"유의수준 5%로 검정했으므로 95% 확실"
```

#### ✅ 올바른 이해

```
α = H₀가 참일 때, 잘못 기각할 확률의 상한

실제 오류 확률은:
- H₀가 실제로 참인지 거짓인지에 따라 다름
- 사전확률에 의존

조건부 확률임을 이해!
```

---

### 오해 4: p > α면 H₀가 참

#### ❌ 잘못된 이해

```
"p = 0.12 > 0.05이므로 귀무가설이 참이다"
"차이가 없다고 증명되었다"
```

#### ✅ 올바른 이해

```
"p = 0.12 > 0.05이므로
 H₀를 기각할 충분한 증거가 없다"

증거 부족 ≠ H₀가 참

"Not guilty" ≠ "Innocent"와 유사
```

---

### 오해 5: 정확히 α = 0.05여야 함

#### ❌ 잘못된 이해

```
"p = 0.052이므로 완전히 의미없음"
"p = 0.048이므로 완벽한 증거"
```

#### ✅ 올바른 이해

```
0.05는 임의의 관습적 기준
경계선에서는 맥락 고려

p = 0.052:
- 기술적으로 비유의
- 하지만 경계선
- 추가 연구 고려
- 효과크기 확인

p = 0.048:
- 기술적으로 유의
- 하지만 경계선
- 과대해석 주의
- 재현성 확인
```

---

## 실전 예제

### 종합 문제 1

#### 문제

```
연구자가 새로운 다이어트 방법의 효과를 검증하려 한다.

- 기존 방법: 평균 5kg 감량
- 새 방법: 30명 실험, 평균 6.5kg 감량, 표준편차 2.0kg
- 유의수준: α = 0.05 (단측검정, 우측)

1. 가설 설정
2. 검정통계량 계산
3. p-value 계산
4. 의사결정
5. 결론 작성
```

#### 풀이

```python
import numpy as np
from scipy import stats

# 주어진 정보
mu_0 = 5  # 기존 방법
sample_mean = 6.5  # 새 방법 평균
sample_std = 2.0
n = 30
alpha = 0.05

print("=== 1. 가설 설정 ===")
print("H₀: μ = 5 (새 방법 효과 없음)")
print("H₁: μ > 5 (새 방법이 더 효과적)")
print(f"유의수준: α = {alpha}\n")

# t-통계량 계산
print("=== 2. 검정통계량 계산 ===")
se = sample_std / np.sqrt(n)
t_stat = (sample_mean - mu_0) / se
df = n - 1

print(f"표준오차 SE = s/√n = {sample_std}/√{n} = {se:.4f}")
print(f"t = (x̄ - μ₀)/SE = ({sample_mean} - {mu_0})/{se:.4f} = {t_stat:.4f}")
print(f"자유도: df = {df}\n")

# p-value 계산
print("=== 3. p-value 계산 ===")
p_value = 1 - stats.t.cdf(t_stat, df)
print(f"p-value = P(t > {t_stat:.4f}) = {p_value:.4f}\n")

# 임계값
t_critical = stats.t.ppf(1-alpha, df)
print(f"임계값 (α={alpha}): {t_critical:.4f}\n")

# 의사결정
print("=== 4. 의사결정 ===")
print(f"방법 1) p-value 비교:")
print(f"  p-value ({p_value:.4f}) < α ({alpha})")
print(f"  → H₀ 기각\n")

print(f"방법 2) 임계값 비교:")
print(f"  t ({t_stat:.4f}) > t_critical ({t_critical:.4f})")
print(f"  → H₀ 기각\n")

# 결론
print("=== 5. 결론 ===")
print(f"새로운 다이어트 방법은 기존 방법보다")
print(f"통계적으로 유의하게 더 효과적이다")
print(f"(평균 {sample_mean}kg vs {mu_0}kg, p = {p_value:.4f})")

# 효과크기
cohens_d = (sample_mean - mu_0) / sample_std
print(f"\n효과크기 (Cohen's d): {cohens_d:.4f}")
if cohens_d < 0.2:
    print("→ 작은 효과")
elif cohens_d < 0.5:
    print("→ 중간 효과")
elif cohens_d < 0.8:
    print("→ 큰 효과")
else:
    print("→ 매우 큰 효과")
```

**출력:**
```
=== 1. 가설 설정 ===
H₀: μ = 5 (새 방법 효과 없음)
H₁: μ > 5 (새 방법이 더 효과적)
유의수준: α = 0.05

=== 2. 검정통계량 계산 ===
표준오차 SE = s/√n = 2.0/√30 = 0.3651
t = (x̄ - μ₀)/SE = (6.5 - 5)/0.3651 = 4.1079
자유도: df = 29

=== 3. p-value 계산 ===
p-value = P(t > 4.1079) = 0.0001

임계값 (α=0.05): 1.6991

=== 4. 의사결정 ===
방법 1) p-value 비교:
  p-value (0.0001) < α (0.05)
  → H₀ 기각

방법 2) 임계값 비교:
  t (4.1079) > t_critical (1.6991)
  → H₀ 기각

=== 5. 결론 ===
새로운 다이어트 방법은 기존 방법보다
통계적으로 유의하게 더 효과적이다
(평균 6.5kg vs 5kg, p = 0.0001)

효과크기 (Cohen's d): 0.7500
→ 큰 효과
```

---

### 종합 문제 2: 다양한 시나리오

#### 시나리오 A

```
t = 2.5, df = 24, 단측검정
α = 0.05

p-value = ?
의사결정 = ?
```

**풀이:**
```python
from scipy import stats

t_stat = 2.5
df = 24
alpha = 0.05

p_value = 1 - stats.t.cdf(t_stat, df)
print(f"시나리오 A:")
print(f"p-value = {p_value:.4f}")
print(f"p ({p_value:.4f}) < α ({alpha})")
print(f"→ H₀ 기각\n")
```

#### 시나리오 B

```
χ² = 5.99, df = 2
α = 0.05

p-value = ?
의사결정 = ?
```

**풀이:**
```python
from scipy import stats

chi2_stat = 5.99
df = 2
alpha = 0.05

p_value = 1 - stats.chi2.cdf(chi2_stat, df)
print(f"시나리오 B:")
print(f"p-value = {p_value:.4f}")
print(f"p ({p_value:.4f}) = α ({alpha})")
print(f"→ 경계선! 상황에 따라 판단\n")
```

#### 시나리오 C

```
z = 1.2 (양측검정)
α = 0.01

p-value = ?
의사결정 = ?
```

**풀이:**
```python
from scipy import stats

z_stat = 1.2
alpha = 0.01

p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))
print(f"시나리오 C:")
print(f"p-value = {p_value:.4f}")
print(f"p ({p_value:.4f}) > α ({alpha})")
print(f"→ H₀ 채택 (기각 실패)\n")
```

---

## 시험 대비 핵심

### 📝 핵심 개념 암기

#### 1. 정의

```
유의수준 (α):
- 제1종 오류의 최대 허용 확률
- 검정 전 설정
- 판단 기준선

유의확률 (p-value):
- H₀ 하에서 관찰된(또는 더 극단적) 결과 확률
- 검정 후 계산
- 증거의 강도
```

#### 2. 의사결정

```
p ≤ α  →  H₀ 기각 (유의함)
p > α  →  H₀ 채택 (유의하지 않음)
```

#### 3. 흔한 값

```
α = 0.05 (표준)
α = 0.01 (엄격)
α = 0.10 (완화)

p < 0.001 (매우 유의)
p < 0.01 (유의)
p < 0.05 (유의)
```

---

### 🎯 자주 나오는 문제 유형

#### 유형 1: 개념 문제

```
Q: 유의수준과 유의확률의 차이는?
A: 
- 유의수준: 사전 설정 기준, 제1종 오류 허용 확률
- 유의확률: 사후 계산, 관찰 결과의 희귀성

Q: p = 0.03의 의미는?
A: 
귀무가설이 참일 때, 이런 극단적 결과가 
나올 확률이 3%
```

#### 유형 2: 계산 문제

```
Q: t = 2.5, df = 20, 단측검정
   p-value를 계산하시오

A:
from scipy import stats
p = 1 - stats.t.cdf(2.5, 20)
# p = 0.0106
```

#### 유형 3: 의사결정 문제

```
Q: α = 0.05, p = 0.03
   의사결정과 결론은?

A:
p (0.03) < α (0.05)
→ H₀ 기각
→ 통계적으로 유의함
```

#### 유형 4: 해석 문제

```
Q: α = 0.05로 검정하여 p = 0.08을 얻었다
   올바른 해석은?

A:
p (0.08) > α (0.05)
→ H₀ 기각 실패 (채택)
→ "효과가 있다는 증거 부족"
→ "효과가 없다"는 ✗ (증명 아님)
```

---

### ⚠️ 자주하는 실수

| 실수 | 올바른 이해 |
|------|-----------|
| ❌ p = H₀가 참일 확률 | ✅ p = 데이터가 나올 확률 (H₀ 가정 하) |
| ❌ p가 작으면 효과 큼 | ✅ p는 유의성, 효과크기 별도 |
| ❌ α = 결과 오류율 | ✅ α = 제1종 오류 허용 상한 |
| ❌ p > α면 H₀ 참 | ✅ p > α면 H₀ 기각 증거 부족 |
| ❌ 0.05만 사용 | ✅ 상황에 따라 다양한 α |

---

### 📊 체크리스트

#### 검정 수행 전

```
□ 가설 설정 (H₀, H₁)
□ 유의수준(α) 결정
□ 검정 방향 (양측/단측)
□ 적절한 검정 방법 선택
```

#### 검정 수행 중

```
□ 데이터 수집
□ 가정 확인 (정규성, 등분산성 등)
□ 통계량 계산
□ p-value 계산
```

#### 검정 수행 후

```
□ p-value와 α 비교
□ 의사결정 (기각/채택)
□ 효과크기 계산
□ 결론 작성
□ 실질적 의미 해석
```

---

### 💡 실전 팁

#### 1. 항상 맥락 고려

```
통계적 유의성 ≠ 실질적 의미

p < 0.05여도:
- 효과크기 확인
- 샘플 크기 고려
- 실무적 중요성 판단
```

#### 2. 경계선 주의

```
p = 0.048 vs p = 0.052
→ 큰 차이 아님
→ 절대적 기준 아님
→ 추가 분석 고려
```

#### 3. 다양한 지표 활용

```
p-value만 아니라:
✓ 신뢰구간
✓ 효과크기
✓ 검정력(Power)
✓ 실질적 의미
```

#### 4. 정확한 표현

```
✅ "통계적으로 유의하다"
✅ "H₀를 기각한다"
✅ "증거가 있다/없다"

❌ "증명되었다"
❌ "확실하다"
❌ "효과가 크다"
```

---

## 요약

### 핵심 정리

```
유의수준 (α):
- 검정 전 설정
- 기각 기준선
- 제1종 오류 허용치
- 보통 0.05

유의확률 (p-value):
- 검정 후 계산
- 증거의 강도
- 관찰 결과의 희귀성
- 데이터 의존

의사결정:
p ≤ α → 기각 (유의)
p > α → 채택 (비유의)
```

### 올바른 해석

```
p = 0.03, α = 0.05:

✅ "H₀가 참이라면 이런 결과는 3%만 발생"
✅ "유의수준 5%에서 통계적으로 유의"
✅ "H₀를 기각할 충분한 증거"

❌ "H₀가 참일 확률 3%"
❌ "효과가 크다"
❌ "증명되었다"
```

### 주의사항

```
⚠️ p-value는 효과크기 아님
⚠️ 통계적 유의 ≠ 실질적 의미
⚠️ 0.05는 절대적 기준 아님
⚠️ 맥락과 효과크기 함께 고려
⚠️ 재현성 중요
```

---

## 참고자료

### 추가 학습 자료
- American Statistical Association의 p-value 성명: https://www.amstat.org/asa/files/pdfs/P-ValueStatement.pdf
- Understanding Statistical Power: https://www.statisticshowto.com/power/
- Effect Size 계산: https://www.psychometrica.de/effect_size.html

### Python 라이브러리
- scipy.stats: 통계 검정
- statsmodels: 고급 통계 분석
- pingouin: 사용자 친화적 통계

---

**작성일**: 2026-02-05  
**버전**: 1.0  
**용도**: 빅데이터분석기사 시험 대비 / 가설검정 학습
